# -*- coding: utf-8 -*-
"""HW2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17_qaytG9smMtTKsvHV9t4uDLcuItsQHH
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/ece60146_hw2/

from PIL import Image # pillow fork
import os
import time
import torch
import torchvision.transforms as tvt
import numpy as np
import random #for random seed
import matplotlib.pyplot as plt #matplotlib for visualisation
from scipy.stats import wasserstein_distance

def manual_scaling(images):
  images_scaled = images/images.max().float()
  return images_scaled

def tvt_scaling(images):
  images_scaled = torch.zeros_like(images).float()
  for i in range(images.shape[0]):
    images_scaled[i] = tvt.ToTensor()(np.transpose(images[i].numpy(), (1,2,0)))
  return images_scaled

images_v1 = torch.randint(0, 32, (4, 3, 5, 9)).type(torch.uint8) #version1 images -> pixel values limited to (0,32)
images_v2 = torch.randint(0, 256, (4, 3, 5, 9)).type(torch.uint8) #version2 images -> pixel values in full one byte range

#v1 manual pixel scaling vs automated (tvt.ToTensor) comparison
manual_images_v1 = manual_scaling(images_v1)
auto_images_v1 = tvt_scaling(images_v1)
print("v1 image first batch comparison output : ")
print((manual_images_v1[0] == auto_images_v1[0]))

#v2 manual pixel scaling vs automated (tvt.ToTensor) comparison
manual_images_v2 = manual_scaling(images_v2)
auto_images_v2 = tvt_scaling(images_v2)
print("v2 image first batch comparison output : ")
print((manual_images_v2[0] == auto_images_v2[0]))

test_img_np_array = np.load('images/test_image.npy')
plt.imshow(test_img_np_array)
print(f'max value in given npy image = {np.amax(test_img_np_array)}')  #print max value in the np array
print(f'min value in given npy image = {np.amin(test_img_np_array)}')  #print min value in the nd array

images_scale_max = manual_scaling(torch.from_numpy(np.transpose(test_img_np_array,(2,0,1)))) #manual scaling scales the image by the max value i.e. 219
images_scale_255 = tvt.ToTensor()(test_img_np_array) #avoiding tvt_scaling function as it iterates through the batches

print("manual scaling output : ")
print(images_scale_max[0])
print()
print("tvt.ToTensor scaling output : ")
print(images_scale_255[0])

#alternatively we can use foll. lines for direct operations on np array
#print(test_img_np_array[0]/np.amax(test_img_np_array))
#print(test_img_np_array[0]/255)

#3.2 Becoming Familiar with torchvision.transforms
calculator_direct = Image.open('images/calculator_direct.jpeg')
calculator_oblique = Image.open('images/calculator_oblique.jpeg')
my_bins = 10
fig, axes = plt.subplots(1, 2, figsize=(6, 5), sharey=False)
axes[0].imshow(calculator_direct)
axes[1].imshow(calculator_oblique)
plt.show()

#calculating histograms
hist_calculator_direct = torch.histc(tvt.ToTensor()(calculator_direct), bins=my_bins, min=0.0, max=1.0)
hist_calculator_direct = hist_calculator_direct.div(hist_calculator_direct.sum())
hist_calculator_oblique = torch.histc(tvt.ToTensor()(calculator_oblique), bins=my_bins, min=0.0, max=1.0)
hist_calculator_oblique = hist_calculator_oblique.div(hist_calculator_oblique.sum())

no_transfomer = tvt.RandomAffine(degrees=(0,0))
img_without_transform = no_transfomer(calculator_oblique)

x_shear = np.linspace(-40, 40, 9)
y_shear = np.linspace(-40, 40, 9)
min_affine_dist = 1e10 #setting value to inf for initial comparison

#calculating Wasserstein Dist
def cal_wasserstein_dist(calculator_trans_img, num_bins = 10):
  hist_calculator_trans_img = torch.histc(tvt.ToTensor()(calculator_trans_img), bins=num_bins, min=0.0, max=1.0)
  hist_calculator_trans_img = hist_calculator_trans_img.div(hist_calculator_trans_img.sum())
  w_dist = wasserstein_distance(hist_calculator_direct.cpu().numpy(), hist_calculator_trans_img.cpu().numpy())
  return w_dist,hist_calculator_trans_img

#Looping throgh different degrees and shear values
for degree in range(-60,60,20):
  for i, x_shear_idx in enumerate(x_shear):
    for j, y_shear_idx in enumerate(y_shear):
      affine_transformer = tvt.RandomAffine(degrees=(degree,degree), translate=(0,0),scale=(1,1),shear = [x_shear_idx, x_shear_idx+5, y_shear_idx, y_shear_idx+5])
      transformed_img = affine_transformer(calculator_oblique)
      w_dist,hist_calculator_trans_img = cal_wasserstein_dist(transformed_img,num_bins=my_bins)
      if w_dist < min_affine_dist:
        min_affine_dist = w_dist
        best_affine_img = transformed_img
        selected_deg = degree
        selected_x_shear = x_shear_idx
        selected_y_shear = y_shear_idx
        hist_trans_img_affine = hist_calculator_trans_img

min_pers_dist = 1e9
W, H = calculator_direct.size
for i in range(15):
  startpoints, endpoints = tvt.RandomPerspective().get_params(W, H, 0.3)
  transformed_img = tvt.functional.perspective(calculator_direct, startpoints, endpoints)
  w_dist,hist_calculator_trans_img = cal_wasserstein_dist(transformed_img,num_bins=my_bins)
  # Comparing Wassertein distance with min value
  if w_dist < min_pers_dist:
    min_pers_dist = w_dist
    best_pers_img = transformed_img
    selected_startpoints = startpoints
    selected_endpoints = endpoints
    hist_trans_img_pers = hist_calculator_trans_img

w_dist_obliqe,_ = cal_wasserstein_dist(calculator_oblique,num_bins=my_bins)
print("the selected affine transformer parameters are : degree={}, x_shear=[{},{}] & y_shear=[{},{}]".format(selected_deg,selected_x_shear,selected_x_shear+5,selected_y_shear,selected_y_shear+5))
print("the selected perspective transformer parameters are : startpoints={} \n \t\t\t\t\t\t endpoints={}".format(selected_startpoints,selected_endpoints))
print("wasserstein_dist bw orig direct image and orig oblique img = {}".format(w_dist_obliqe))
print("wasserstein_dist bw orig direct image and affine transformed img = {}".format(min_affine_dist))
print("wasserstein_dist bw orig direct image and perspective transformed img = {}".format(min_pers_dist))
# Plot Best Image after Affine Transform
fig, axes = plt.subplots(1, 4, figsize=(8, 5), sharey=True)
axes[0].imshow(calculator_direct)
axes[0].set_title('Orig Direct Img')
axes[1].imshow(calculator_oblique)
axes[1].set_title('Orig Oblique Img')
axes[2].imshow(best_affine_img)
axes[2].set_title('Best Aff-Trans Img')
axes[3].imshow(best_pers_img)
axes[3].set_title('Best Persp-Trans Img')
plt.show()

#histogram plots
x = range(my_bins)
fig, axes = plt.subplots(1, 4, figsize=(8, 5), sharey=False)
axes[0].bar(x, hist_calculator_direct, align='center')
axes[1].bar(x, hist_calculator_oblique, align='center')
axes[2].bar(x, hist_trans_img_affine, align='center')
axes[3].bar(x, hist_trans_img_pers, align='center')

axes[0].set_title('Hist Direct Img')
axes[1].set_title('Hist Oblique Img')
axes[2].set_title('Hist Affine. Img')
axes[3].set_title('Hist Persp. Img')

#3.3 Creating Your Own Dataset Class
class MyDataset(torch.utils.data.Dataset):
  def __init__(self, root):
    super().__init__()
    # Obtain file names
    # perform data augmentation transforms, etc.
    self.root_dir = root
    self.image_paths = os.listdir(self.root_dir)
    self.transforms = tvt.Compose([tvt.ToTensor(),
                                  tvt.RandomGrayscale(p=0.5),
                                  tvt.RandomResizedCrop(256, scale=(0.9, 1.0)),
                                  tvt.GaussianBlur(5, sigma=(0.5, 2.0))])
  def __len__(self):
    # Return the total number of images
    return len(self.image_paths)

  def __getitem__(self, index):
    # Read an image at index and perform augmentations
    # Return the tuple : ( augmented tensor , integer label )
    # Get the path of the image
    # As we have only 10 images, we used "index % 10" to cover the cases when index >= 10
    index = index % len(self.image_paths)
    image_name = self.image_paths[index]
    full_image_path = os.path.join(self.root_dir, image_name)
    my_image = Image.open(full_image_path)
    transformed_image = self.transforms(my_image)
    return (transformed_image, index)

#test input demo
my_dataset = MyDataset(root = '/content/drive/MyDrive/ece60146_hw2/images/ten_images')
print(len(my_dataset))
index = 10
print(my_dataset[index][0].shape, my_dataset[index][1])
index = 55
print(my_dataset[index][0].shape, my_dataset[index][1])

# PLot three original images with augement versions
fig, axes = plt.subplots(3, 2, figsize=(10, 12), sharey=True)
rand_indices = np.random.randint(0, len(my_dataset), 3) #obtain 3 random images from our image set
for i in range(0,3):
  index = rand_indices[i]
  img, label = my_dataset[index]
  original_image = Image.open(os.path.join(my_dataset.root_dir, my_dataset.image_paths[index]))
  resized_image = original_image.resize((256, 256))
  axes[i][0].imshow(resized_image)
  axes[i][0].set_title('Original Image')
  axes[i][1].imshow(np.array(img).transpose(1,2,0))
  axes[i][1].set_title('Augmented Image')

batch_size = 4
my_dataloader = torch.utils.data.DataLoader(dataset=my_dataset, batch_size=batch_size, shuffle=True, num_workers = 2)
iterator = iter(my_dataloader) #iter is a special function defined in Dataloader class, hence it is not overridden in MyDataset class
batch = next(iterator)
fig, axes = plt.subplots(1, batch_size, figsize=(12, 8), sharey=True)
for i in range(0,batch_size):
  image_in_batch = batch[0][i]
  axes[i].imshow(np.array(image_in_batch).transpose(1,2,0))
plt.show()

#comparing the performance gain by using the multi-threaded DataLoader v.s. just using Dataset
num_iters = 1000
batch_size_list = [32,64]
num_workers_list = [2, 4]

#performance gain by using the MyDataset __get_item__
rand_indices = np.random.randint(len(my_dataset), size = num_iters)
start_time = time.time()
for i in rand_indices:
  rand_image, label = my_dataset[i]
end_time = time.time()
elapsed_time = end_time - start_time
print(f'Time taken to process {num_iters} images in the dataset using __get_item__: {elapsed_time} seconds\n')

#performance gain by using the multi-threaded DataLoader
for bsize in batch_size_list :
  for nworkers in num_workers_list:
    print(f'Performance of dataloader with batch size {bsize} and {nworkers} num_workers:')
    dataloader = torch.utils.data.DataLoader(dataset=my_dataset,
                batch_size=bsize, shuffle=True, num_workers = nworkers)
    iterator = iter(dataloader)
    start_time = time.time()
    for i in range(int(num_iters/bsize)):
      try:
        image, label = next(iterator)
      except StopIteration:
        iterator = iter(dataloader)
        image, label = next(iterator)
    end_time = time.time()
    elapsed_time = end_time - start_time
    print(f'Time taken to process {num_iters} images in the dataset using Dataloder: {elapsed_time} seconds]\n')

batch_size = 2
dataloader = torch.utils.data.DataLoader(my_dataset, batch_size = batch_size, shuffle = True)

#Plot the first batch of images
for batch in dataloader :
  images,labels = batch
  fig, axes = plt.subplots(1, batch_size, figsize=(8, 8), sharey=True)
  for i in range(0,batch_size):
    image_in_batch = images[i]
    axes[i].imshow(np.array(image_in_batch).transpose(1,2,0))
  plt.show()
  break

# Rerun the iterator
for batch in dataloader :
  images,labels = batch
  fig, axes = plt.subplots(1, batch_size, figsize=(8, 8), sharey=True)
  for i in range(0,batch_size):
    image_in_batch = images[i]
    axes[i].imshow(np.array(image_in_batch).transpose(1,2,0))
  plt.show()
  break

seed = 60146
random.seed(seed)
torch.manual_seed(seed)
torch.cuda.manual_seed(seed)
np.random.seed(seed)
torch.backends.cudnn.deterministic=True
torch.backends.cudnn.benchmarks=False
os.environ['PYTHONHASHSEED'] = str(seed)

batch_size = 2
dataloader = torch.utils.data.DataLoader(my_dataset, batch_size = batch_size, shuffle = True)
#Plot the first batch of images
for batch in dataloader :
  images,labels = batch
  fig, axes = plt.subplots(1, batch_size, figsize=(8, 8), sharey=True)
  for i in range(0,batch_size):
    image_in_batch = images[i]
    axes[i].imshow(np.array(image_in_batch).transpose(1,2,0))
  plt.show()
  break


# Rerun the iterator
for batch in dataloader :
  images,labels = batch
  fig, axes = plt.subplots(1, batch_size, figsize=(8, 8), sharey=True)
  for i in range(0,batch_size):
    image_in_batch = images[i]
    axes[i].imshow(np.array(image_in_batch).transpose(1,2,0))
  plt.show()
  break

#test to demonstrate the reproducibility of the results
seed = 60146
random.seed(seed)
torch.manual_seed(seed)
torch.cuda.manual_seed(seed)
np.random.seed(seed)
torch.backends.cudnn.deterministic=True
torch.backends.cudnn.benchmarks=False
os.environ['PYTHONHASHSEED'] = str(seed)

batch_size = 2
dataloader = torch.utils.data.DataLoader(my_dataset, batch_size = batch_size, shuffle = True)
#Plot the first batch of images
for batch in dataloader :
  images,labels = batch
  fig, axes = plt.subplots(1, batch_size, figsize=(8, 8), sharey=True)
  for i in range(0,batch_size):
    image_in_batch = images[i]
    axes[i].imshow(np.array(image_in_batch).transpose(1,2,0))
  plt.show()
  break


# Rerun the iterator
for batch in dataloader :
  images,labels = batch
  fig, axes = plt.subplots(1, batch_size, figsize=(8, 8), sharey=True)
  for i in range(0,batch_size):
    image_in_batch = images[i]
    axes[i].imshow(np.array(image_in_batch).transpose(1,2,0))
  plt.show()
  break

