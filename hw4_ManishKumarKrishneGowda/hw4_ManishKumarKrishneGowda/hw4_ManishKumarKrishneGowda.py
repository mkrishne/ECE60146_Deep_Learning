# -*- coding: utf-8 -*-
"""HW4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ql-hAMqItDuTMzTN7X8qfJYssZVMDj35
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/My Drive/hw4_data/

!wget -O DLStudio-2.2.3.tar.gz \
    https://engineering.purdue.edu/kak/distDLS/DLStudio-2.2.3.tar.gz?download

!tar -xvf DLStudio-2.2.3.tar.gz

# Commented out IPython magic to ensure Python compatibility.
# %cd DLStudio-2.2.3

!pip install pymsgbox

!python setup.py install

!pip install pycocotools

import os
import torch
import random
import numpy as np
import requests
import matplotlib.pyplot as plt

from tqdm import tqdm
from PIL import Image
from pycocotools.coco import COCO

!pwd

!python '/content/drive/My Drive/hw4_data/DLStudio-2.2.3/Examples/playing_with_cifar10.py'

seed = 60146
random.seed(seed)
np.random.seed(seed)

from DLStudio import *

!mkdir /content/drive/MyDrive/hw4_data/coco
!wget --no-check-certificate http://images.cocodataset.org/annotations/annotations_trainval2017.zip \
    -O /content/drive/MyDrive/hw4_data/coco/annotations_trainval2017.zip

!unzip /content/drive/MyDrive/hw4_data/coco/annotations_trainval2017.zip -d /content/drive/MyDrive/hw4_data/coco/

!mkdir /content/drive/MyDrive/hw4_data/coco/train2017
!mkdir /content/drive/MyDrive/hw4_data/coco/val2017
!mkdir /content/drive/MyDrive/hw4_data/saved_models

# ImageDownloader class for downloading COCO images
class ImageDownloader():
  def __init__(self, root_dir, annotation_path, classes, imgs_per_class):
    self.root_dir = root_dir
    self.annotation_path = annotation_path
    self.classes = classes
    self.images_per_class = imgs_per_class
    self.class_dir = {}
    self.coco = COCO(self.annotation_path)

  #Create directories same as category names to save images
  def create_dir(self):
    """Creates directories for each class."""
    for c in self.classes:
        dir_path = os.path.join(self.root_dir, c)
        os.makedirs(dir_path, exist_ok=True)  # Create only if not existing
        self.class_dir[c] = dir_path

  # Download images
  def download_images(self, download = True, val = False):
    img_paths = {}
    for c in tqdm(self.classes):
      class_id = self.coco.getCatIds(c)
      img_id = self.coco.getImgIds(catIds=class_id)
      imgs = self.coco.loadImgs(img_id)
      img_paths[c] = []

      # Get indices for training or validation split
      indices = np.arange(self.images_per_class) if not val else np.arange(len(imgs) - self.images_per_class, len(imgs))

      for i in indices:
        img_path = os.path.join(self.root_dir, c, imgs[i]['file_name'])
        if download:
          self.download_image(img_path, imgs[i]['coco_url'])
          self.resize_image(img_path)
        img_paths[c].append(img_path)

    return img_paths

  #Download image from URL using requests
  def download_image(self, path, url):
    try:
      img_data = requests.get(url).content
      with open(path, 'wb') as f:
          f.write(img_data)
      return True
    except Exception as e:
      print(f"Caught exception: {e}")
    return False

  # Resize image
  def resize_image(self, path, size = (64, 64)):
    im = Image.open(path)
    if im.mode != "RGB":
      im = im.convert(mode="RGB")
    im_resized = im.resize(size, Image.BOX)
    im_resized.save(path)

#First set to true to download images, later download=False to not re-download
classes = ['boat', 'cake', 'couch', 'dog', 'motorcycle']
train_imgs_per_class = 1500
val_imgs_per_class = 500

# Download training images
train_downloader = ImageDownloader('/content/drive/MyDrive/hw4_data/coco/train2017',
                '/content/drive/MyDrive/hw4_data/coco/annotations/instances_train2017.json',
                classes, train_imgs_per_class)
train_downloader.create_dir()
train_img_paths = train_downloader.download_images(download = False)

# Download validation images
val_downloader = ImageDownloader('/content/drive/MyDrive/hw4_data/coco/val2017',
                '/content/drive/MyDrive/hw4_data/coco/annotations/instances_train2017.json',
                classes, val_imgs_per_class)
val_downloader.create_dir()
val_img_paths = val_downloader.download_images(download = False, val = True)

plt.style.use('seaborn')  # Consistent and visually appealing color scheme

# Plot sample training images
fig, axes = plt.subplots(5, 3, figsize=(9, 15))
fig.suptitle('Sample training images from COCO dataset', fontsize=16)

for i, cls in enumerate(classes):
    for j, path in enumerate(train_img_paths[cls][:3]):
        im = Image.open(path)
        axes[i][j].imshow(im)
        axes[i][j].set_title(cls)
        axes[i][j].axis('off')  # Remove axes for cleaner visualization

plt.tight_layout(pad=2)  # Adjust spacing between subplots
plt.show()

# Print a line separation
print("-" * 100)  # Print 80 hyphens to create a visual separator

# Plotting sample validation images
fig, axes = plt.subplots(5, 3, figsize=(9, 15))
fig.suptitle('Sample validation images from COCO dataset', fontsize=16)

for i, cls in enumerate(classes):
    for j, path in enumerate(val_img_paths[cls][:3]):
        im = Image.open(path)
        axes[i][j].imshow(im)
        axes[i][j].set_title(cls)
        axes[i][j].axis('off')  # Remove axes for cleaner visualization

plt.tight_layout(pad=2)  # Adjust spacing between subplots
plt.show()

import os
import torch

# Custom dataset class for COCO
class CocoDataset(torch.utils.data.Dataset):
  def __init__(self, root, transforms=None):
    super().__init__()
    self.root_dir = root
    self.classes = os.listdir(self.root_dir)
    self.transforms = transforms
    self.img_paths = []
    self.img_labels = []
    self.class_to_idx = {'boat':0, 'cake':1, 'couch':2, 'dog':3, 'motorcycle': 4}
    self.idx_to_class = {i:c for c, i in self.class_to_idx.items()}

    for cls in self.classes:
      cls_dir = os.path.join(self.root_dir, cls)
      paths = os.listdir(cls_dir)
      self.img_paths+= [os.path.join(cls_dir, path) for path in paths]
      self.img_labels+=[self.class_to_idx[cls]]*len(paths)

  def __len__(self):
    # Return the total number of images
    return len(self.img_paths)

  def __getitem__(self, index):
    index = index % len(self.img_paths)
    img_path = self.img_paths[index]
    img_label = self.img_labels[index]
    img = Image.open(img_path)
    img_transformed = self.transforms(img)
    return img_transformed, img_label

import torchvision.transforms as tvt
import torch.utils.data

# Define image transformations
reshape_size = 64
transforms = tvt.Compose([
    tvt.ToTensor(),  # Convert images to PyTorch tensors
    tvt.Resize((reshape_size, reshape_size)),  # Resize to 64x64
    tvt.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize for better training
])

# Assuming CocoDataset is a custom class you've defined
train_dataset = CocoDataset('/content/drive/MyDrive/hw4_data/coco/train2017/', transforms=transforms)
val_dataset = CocoDataset('/content/drive/MyDrive/hw4_data/coco/val2017/', transforms=transforms)

# Create dataloaders with appropriate settings
train_data_loader = torch.utils.data.DataLoader(train_dataset,
                                                 batch_size=128,
                                                 shuffle=True,  # Shuffle for training
                                                 num_workers=2)  # Use multiple workers for faster loading
val_data_loader = torch.utils.data.DataLoader(val_dataset,
                                                batch_size=128,
                                                shuffle=False,  # No shuffling for validation
                                                num_workers=2)

# Check dataloader output
train_loader_iter = iter(train_data_loader)
img, target = next(train_loader_iter)

print('img has length: ', len(img))  # Print batch size
print('target has length: ', len(target))  # Print batch size (should match img length)
print(img[0].shape)  # Print shape of a single image (should be torch.Size([3, 64, 64]))

import os

def train_net(device, net, optimizer, criterion, data_loader, model_name,
              epochs=10, display_interval=100):
    """Trains a neural network classifier.

    Args:
        device (torch.device): Device to use for training.
        net (torch.nn.Module): Neural network model to train.
        optimizer (torch.optim.Optimizer): Optimizer to use for training.
        criterion (torch.nn.Module): Loss function to use for training.
        data_loader (torch.utils.data.DataLoader): Data loader for training data.
        model_name (str): Name of the model to save.
        epochs (int, optional): Number of training epochs. Defaults to 10.
        display_interval (int, optional): Interval to display training progress. Defaults to 100.
    """

    net = net.to(device)  # Move model to device
    loss_running_record = []  # Track loss for visualization

    for epoch in range(epochs):
        running_loss = 0.0

        for i, data in enumerate(data_loader):
            inputs, labels = data
            inputs = inputs.to(device)
            labels = labels.to(device)

            optimizer.zero_grad()  # Clear gradients
            outputs = net(inputs)  # Forward pass
            loss = criterion(outputs, labels)  # Calculate loss
            loss.backward()  # Backward pass
            optimizer.step()  # Update model parameters

            running_loss += loss.item()  # Accumulate loss

            if (i + 1) % display_interval == 0:
                avg_loss = running_loss / display_interval
                print(f"[epoch : {epoch + 1}, batch : {i + 1}] loss : {avg_loss:.3f}")
                loss_running_record.append(avg_loss)
                running_loss = 0.0  # Reset running loss

    # Save model checkpoint
    checkpoint_path = os.path.join('/content/drive/MyDrive/hw4_data/saved_models', f'{model_name}.pth')
    torch.save(net.state_dict(), checkpoint_path)

    return loss_running_record

import matplotlib.pyplot as plt

def plot_loss(loss, display_interval, model_name):
    """Plots the training loss curve.

    Args:
        loss (list): List of loss values recorded during training.
        display_interval (int): Interval at which loss values were recorded.
        model_name (str): Name of the model being trained.
    """

    iterations = np.arange(len(loss)) * display_interval  # Calculate iterations

    plt.figure(figsize=(8, 6))  # Set plot size
    plt.plot(iterations, loss, label='Training Loss')

    plt.title(f'Training Loss for {model_name}', fontsize=16)  # Set title
    plt.xlabel('Iterations', fontsize=14)  # Set x-axis label
    plt.ylabel('Loss', fontsize=14)  # Set y-axis label

    plt.xlim(0, iterations.max())  # Adjust x-axis limits
    plt.grid(True)  # Add grid lines
    plt.legend()  # Show legend
    plt.tight_layout()  # Adjust layout for better spacing
    plt.show()

def validate_net(device, net, data_loader, model_path=None):
    """Validates a neural network classifier.

    Args:
        device (torch.device): Device to use for validation.
        net (torch.nn.Module): Neural network model to validate.
        data_loader (torch.utils.data.DataLoader): Data loader for validation data.
        model_path (str, optional): Path to load model weights from. Defaults to None.

    Returns:
        tuple: A tuple containing:
            - imgs (list): List of validation images.
            - all_labels (list): List of ground truth labels.
            - all_pred (list): List of predicted labels.
    """

    if model_path is not None:
        net.load_state_dict(torch.load(model_path))

    net = net.to(device)  # Move model to device
    net.eval()  # Set model to evaluation mode

    running_loss = 0.0
    iters = 0
    imgs = []
    all_labels = []
    all_pred = []

    with torch.no_grad():  # Disable gradient calculation for validation
        for i, data in enumerate(data_loader):
            inputs, labels = data
            inputs = inputs.to(device)
            labels = labels.to(device)

            outputs = net(inputs)  # Forward pass
            loss = criterion(outputs, labels)  # Calculate loss

            running_loss += loss.item()  # Accumulate loss
            iters += 1

            pred_labels = torch.argmax(outputs.data, axis=1)  # Get predicted labels
            all_labels.extend(labels.tolist())  # Collect ground truth labels
            all_pred.extend(pred_labels.tolist())  # Collect predicted labels
            imgs.extend(inputs.cpu().detach().numpy())  # Collect images (move to CPU and detach)

    avg_loss = running_loss / iters  # Calculate average validation loss
    print(f"Validation Loss: {avg_loss:.4f}")

    return imgs, all_labels, all_pred

def calc_confusion_matrix(num_classes, actual, predicted):
    """Calculates the confusion matrix.

    Args:
        num_classes (int): Number of classes in the dataset.
        actual (list): List of ground truth labels.
        predicted (list): List of predicted labels.

    Returns:
        np.ndarray: The confusion matrix as a NumPy array.
    """

    conf_mat = np.zeros((num_classes, num_classes), dtype=int)  # Initialize with integer dtype

    for a, p in zip(actual, predicted):
        conf_mat[a, p] += 1  # Increment corresponding cell using double indexing

    return conf_mat

import seaborn as sns

def plot_conf_mat(conf_mat, classes, model_name):
    """Plots the confusion matrix.

    Args:
        conf_mat (np.ndarray): The confusion matrix to plot.
        classes (list): List of class names.
        model_name (str): Name of the model being evaluated.
    """

    num_classes = len(classes)

    # Calculate normalized counts and percentages for annotations
    labels = np.asarray([
        f"{count}\n{percent:.1f}%" for row in conf_mat for count, percent in zip(row, row / np.sum(row) * 100)
    ]).reshape(num_classes, num_classes)

    plt.figure(figsize=(8, 6))  # Adjust figure size for better readability
    sns.heatmap(
        conf_mat,
        annot=labels,
        fmt="",
        cmap="YlOrBr",
        cbar=True,
        xticklabels=classes,
        yticklabels=classes,
        linewidths=0.5,  # Add thin lines between cells for clarity
    )

    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    plt.title(f'Confusion Matrix for {model_name}', fontsize=16)  # Increase title font size
    plt.tight_layout()  # Adjust layout for better spacing
    plt.show()

import torch.nn as nn
import torch.nn.functional as F

class HW4Net(nn.Module):
    """Neural network model 1 for HW4."""

    def __init__(self):
        super().__init__()  # Use super() for conciseness

        # Convolutional layers
        self.conv1 = nn.Conv2d(3, 16, 3)  # Add padding for consistent output size
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(16, 32, 3) # default padding = 0

        # Fully connected layers
        self.fc1 = nn.Linear(6272, 64)  # Consider calculating input size dynamically
        self.fc2 = nn.Linear(64, 5)

    def forward(self, x): # (B, 3, 64, 64)
        x = self.pool(F.relu(self.conv1(x)))  # (B, 16, 62, 62) ->  (B, 16, 31, 31) #(input_size + 2*padding - window_size)+1
        x = self.pool(F.relu(self.conv2(x))) # (B, 32, 29, 29) ->  (B, 32, 14, 14)
        x = x.view(x.shape[0], -1) # (B, 6272)
        x = F.relu(self.fc1(x)) #(B, 64)
        x = self.fc2(x) # (B, 5)
        return x

# Use GPU if available
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Initialize model, optimizer, and criterion
net = HW4Net().to(device)  # Move model to device
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(net.parameters(), lr=1e-3, betas=(0.9, 0.999))

# Training
epochs = 20
display_interval = 5
net1_losses = train_net(device, net, optimizer=optimizer, criterion=criterion,
                        data_loader=train_data_loader, model_name='net1',
                        epochs=epochs, display_interval=display_interval)

# Validation
save_path = '/content/drive/MyDrive/hw4_data/saved_models/net1.pth'
imgs, actual, predicted = validate_net(device, net, val_data_loader, model_path=save_path)

# Calculate confusion matrix and accuracy
conf_mat = calc_confusion_matrix(5, actual, predicted)
print(conf_mat)
accuracy1 = np.trace(conf_mat) / float(np.sum(conf_mat))
print(f"Accuracy: {accuracy1:.4f}")

# Plot confusion matrix
plot_conf_mat(conf_mat, classes, 'Net1')

import torch.nn as nn
import torch.nn.functional as F

class Net2(nn.Module):
    """Neural network model with improved structure and clarity."""

    def __init__(self):
        super().__init__()  # Use super() for conciseness

        #Convolutional layers with padding for consistent output size
        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)

        # Fully connected layers with dynamic input size calculation
        self.fc1 = nn.Linear(self._calculate_fc_input_size(), 64)  # Calculate input size dynamically
        self.fc2 = nn.Linear(64, 5)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(x.shape[0], -1)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

    def _calculate_fc_input_size(self):
        """Helper function to calculate input size for the first fully connected layer."""
        with torch.no_grad():
            x = torch.randn(1, 3, 64, 64)  # Assume input size of 3x64x64
            x = self.pool(F.relu(self.conv1(x))) #(B, 3, 64, 64) ->  (B, 16, 32, 32)
            x = self.pool(F.relu(self.conv2(x))) #(B, 16, 32, 32) ->  (B, 32, 16, 16)
            x = x.view(x.shape[0], -1) #(B,8192)
            return x.shape[1]

# Initialize Net2
net2 = Net2().to(device)  # Move model to device immediately

# Criterion and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(net2.parameters(), lr=1e-3, betas=(0.9, 0.999))

# Training
epochs = 20
display_interval = 5
net2_losses = train_net(device, net2, optimizer=optimizer, criterion=criterion,
                        data_loader=train_data_loader, model_name='net2',
                        epochs=epochs, display_interval=display_interval)

# Validation
save_path = '/content/drive/MyDrive/hw4_data/saved_models/net2.pth'
imgs, actual, predicted = validate_net(device, net2, val_data_loader, model_path=save_path)

# Calculate confusion matrix and accuracy
conf_mat = calc_confusion_matrix(5, actual, predicted)
print(conf_mat)
accuracy2 = np.trace(conf_mat) / float(np.sum(conf_mat))
print(f"Accuracy: {accuracy2:.4f}")

# Plot confusion matrix
plot_conf_mat(conf_mat, classes, 'Net2')

import torch.nn as nn
import torch.nn.functional as F

class Net3(nn.Module):
    def __init__(self):
        super().__init__()

        # Convolutional layers using ModuleList
        self.conv_list = nn.ModuleList([
            nn.Conv2d(3, 16, 3, padding=1),
            nn.MaxPool2d(2, 2),
            nn.Conv2d(16, 32, 3, padding=1),
            nn.MaxPool2d(2, 2),
            *[nn.Conv2d(32, 32, 3, padding=1) for _ in range(10)]  # Define all 10 Conv2d layers
        ])

        # Fully connected layers
        self.fc1 = nn.Linear(self._calculate_fc_input_size(), 64)  # Input size might need adjustment
        self.fc2 = nn.Linear(64, 5)

    def forward(self, x):
        for i, layer in enumerate(self.conv_list):
            if isinstance(layer, nn.Conv2d):
                x = F.relu(layer(x))
            else:  # Assuming it's a MaxPool2d layer
                x = layer(x)

            # Apply the 10 Conv2d layers after the initial 4 layers
            if i == 4:
                for conv_layer in self.conv_list[5:]:  # Iterate through layers 5 to 14
                    x = F.relu(conv_layer(x))
                break  # Exit the outer loop

        x = x.view(x.shape[0], -1)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

    def _calculate_fc_input_size(self):
        """Helper function to calculate input size for the first fully connected layer."""
        with torch.no_grad():
            x = torch.randn(1, 3, 64, 64)  # Assume input size of 3x64x64
            x = nn.MaxPool2d(2, 2)(F.relu(self.conv_list[0](x))) #(B, 3, 64, 64) ->  (B, 16, 32, 32)
            x = nn.MaxPool2d(2, 2)(F.relu(self.conv_list[2](x))) #(B, 16, 32, 32) ->  (B, 32, 16, 16)
            x = x.view(x.shape[0], -1) #(B,8192)
            return x.shape[1]

import torch.nn as nn
import torch.nn.functional as F

class Net4(nn.Module):
    """Neural network model with enhanced structure and potential for regularization."""

    def __init__(self):
        super().__init__()

        # Convolutional layers with padding for consistent output size
        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)
        self.conv3 = nn.Conv2d(32, 32, 3, padding=1)  # Add padding for consistent output

        # Fully connected layers with dynamic input size calculation
        self.fc1 = nn.Linear(self._calculate_fc_input_size(), 64)  # Calculate input size dynamically
        self.fc2 = nn.Linear(64, 5)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))

        # Residual connection for potential improvement
        x_residual = x  # Store residual for later addition
        for _ in range(10):
            x = F.relu(self.conv3(x))
        x = x + x_residual  # Add residual connection

        x = x.view(x.shape[0], -1)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

    def _calculate_fc_input_size(self):
        """Helper function to calculate input size for the first fully connected layer."""
        with torch.no_grad():
            x = torch.randn(1, 3, 64, 64)  # Assume input size
            x = self.pool(F.relu(self.conv1(x)))
            x = self.pool(F.relu(self.conv2(x)))
            x = self.conv3(x)  # Apply conv3 once for calculation
            x = x.view(x.shape[0], -1)
            return x.shape[1]

# Initialize Net3
net3 = Net3().to(device)  # Move model to device immediately

# Criterion and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(net3.parameters(), lr=1e-3, betas=(0.9, 0.999))

# Training
epochs = 20
display_interval = 5
net3_losses = train_net(device, net3, optimizer=optimizer, criterion=criterion,
                        data_loader=train_data_loader, model_name='net3',
                        epochs=epochs, display_interval=display_interval)

# Validation
save_path = '/content/drive/MyDrive/hw4_data/saved_models/net3.pth'
imgs, actual, predicted = validate_net(device, net3, val_data_loader, model_path=save_path)

# Calculate confusion matrix and accuracy
conf_mat = calc_confusion_matrix(5, actual, predicted)
print(conf_mat)
accuracy3 = np.trace(conf_mat) / float(np.sum(conf_mat))
print(f"Accuracy: {accuracy3:.4f}")

# Plot confusion matrix
plot_conf_mat(conf_mat, classes, 'Net3')

# Initialize Net3
net4 = Net4().to(device)  # Move model to device immediately

# Criterion and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(net4.parameters(), lr=1e-3, betas=(0.9, 0.999))

# Training
epochs = 20
display_interval = 5
net4_losses = train_net(device, net4, optimizer=optimizer, criterion=criterion,
                        data_loader=train_data_loader, model_name='net4',
                        epochs=epochs, display_interval=display_interval)

# Validation
save_path = '/content/drive/MyDrive/hw4_data/saved_models/net4.pth'
imgs, actual, predicted = validate_net(device, net4, val_data_loader, model_path=save_path)

# Calculate confusion matrix and accuracy
conf_mat = calc_confusion_matrix(5, actual, predicted)
print(conf_mat)
accuracy4 = np.trace(conf_mat) / float(np.sum(conf_mat))
print(f"Accuracy: {accuracy4:.4f}")

# Plot confusion matrix
plot_conf_mat(conf_mat, classes, 'Net4')

# Ensure consistent color scheme across plots
plt.style.use('seaborn')  # Consistent and aesthetically pleasing colors

# Create the plot
plt.figure(figsize=(8, 6))  # Set appropriate figure size
x = np.arange(len(net1_losses)) * display_interval
plt.plot(x, net1_losses, label='Net1', linewidth=2)  # Adjust linewidth
plt.plot(x, net2_losses, label='Net2', linewidth=2)
plt.plot(x, net3_losses, label='Net3', linewidth=2)
plt.plot(x, net4_losses, label='Net4', linewidth=2)

# Customize plot elements
plt.title('Training CNN Classifiers', fontsize=16)  # Increase title font size
plt.xlabel('Iterations', fontsize=14)  # Set x-axis label
plt.ylabel('Loss', fontsize=14)  # Set y-axis label
plt.xticks(fontsize=12)  # Adjust tick label size
plt.yticks(fontsize=12)
plt.grid(True)  # Add grid lines for readability
plt.legend(fontsize=12)  # Show legend

# Ensure tight layout for optimal spacing
plt.tight_layout()

# Display the plot
plt.show()

import pandas as pd

# Calculate model parameters
net1_params = sum(p.numel() for p in net.parameters() if p.requires_grad)
net2_params = sum(p.numel() for p in net2.parameters() if p.requires_grad)
net3_params = sum(p.numel() for p in net3.parameters() if p.requires_grad)


# Create the table
data = {
    'Net Name': ['Net1', 'Net2', 'Net3', 'Net4'],
    'Number of Parameters': [net1_params, net2_params, net3_params, net3_params],
    'Classification Accuracy': [accuracy1, accuracy2, accuracy3, accuracy4]  # Replace with actual accuracy values
}

table = pd.DataFrame(data)
print(table.to_string())