# -*- coding: utf-8 -*-
"""HW3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vHji54AmefOnbBQDkNU-9kFbGqs5Ebtn
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
import os
import random
import torch
import numpy as np
import sys

!sudo python3 setup.py install
sys.path.append( "/content/drive/My Drive/hw3_data/ComputationalGraphPrimer-1.1.3/ComputationalGraphPrimer" )
# %cd /content/drive/My Drive/hw3_data/ComputationalGraphPrimer-1.1.3
print(sys.path)

seed = 60146
random.seed(seed)
torch.manual_seed(seed)
torch.cuda.manual_seed(seed)
np.random.seed(seed)
torch.backends.cudnn.deterministic=True
torch.backends.cudnn.benchmarks=False
os.environ['PYTHONHASHSEED'] = str(seed)

import operator
#This class inherits the main ComputationalGraphPrimer. It has the term "partial_of_loss_wrt_param" division corrected
class ComputationalGraphPrimerBatchDiv(ComputationalGraphPrimer):
  def __init__(self, *args, **kwargs):
    super(ComputationalGraphPrimerBatchDiv, self).__init__(*args, **kwargs)
  def backprop_and_update_params_one_neuron_model(self, data_tuples_in_batch, predictions, y_errors_in_batch, deriv_sigmoids):
      """
      This function implements the equations shown on Slide 61 of my Week 3 presentation in our DL
      class at Purdue.  All four parameters defined above are lists of what was either supplied to the
      forward prop function or calculated by it for each training data sample in a batch.
      """
      input_vars = self.independent_vars
      input_vars_to_param_map = self.var_to_var_param[self.output_vars[0]]                  ## These two statements align the
      param_to_vars_map = {param : var for var, param in input_vars_to_param_map.items()}   ##   the input vars
      vals_for_learnable_params = self.vals_for_learnable_params
      for i,param in enumerate(self.vals_for_learnable_params):
          ## For each param, sum the partials from every training data sample in batch
          partial_of_loss_wrt_param = 0.0
          for j in range(self.batch_size):
              vals_for_input_vars_dict =  dict(zip(input_vars, list(data_tuples_in_batch[j])))
              partial_of_loss_wrt_param   +=   -  y_errors_in_batch[j] * vals_for_input_vars_dict[param_to_vars_map[param]] * deriv_sigmoids[j]
          partial_of_loss_wrt_param /=  float(self.batch_size)
          step = self.learning_rate * partial_of_loss_wrt_param
          ## Update the learnable parameters
          self.vals_for_learnable_params[param] += step
      y_error_avg = sum(y_errors_in_batch) / float(self.batch_size)
      deriv_sigmoid_avg = sum(deriv_sigmoids) / float(self.batch_size)
      self.bias += self.learning_rate * y_error_avg * deriv_sigmoid_avg    ## Update the bias

    ######################################################################################################

#training_iterations=40000, batch_size=8, learning_rate=1e-3
#equivalent to running one_neuron_classifier.py
cgp = ComputationalGraphPrimerBatchDiv(
               one_neuron_model = True,
               expressions = ['xw=ab*xa+bc*xb+cd*xc+ac*xd'],
               output_vars = ['xw'],
               dataset_size = 5000,
               learning_rate = 1e-3,
               training_iterations = 40000,
               batch_size = 8,
               display_loss_how_often = 100,
               debug = True,
      )

cgp.parse_expressions()

cgp.display_one_neuron_network()

training_data = cgp.gen_training_data()

cgp.run_training_loop_one_neuron_model( training_data )

#set for one neuron model, with same parameters as that for one_neuron_classifier.py as above
#Equivalent to running verify_with_torchnn.py with above params

cgp = ComputationalGraphPrimer(
               for_verification_only = True,
               expressions = ['xw=ab*xa+bc*xb+cd*xc+ac*xd'],   # Only used to determine the data dimensionality
               output_vars = ['xw'],
               dataset_size = 5000,
               learning_rate = 1e-3,             # For the one-neuron option below
               training_iterations = 40000,
               batch_size = 8,
               display_loss_how_often = 100,
               debug=True
      )

cgp.parse_expressions()

training_data = cgp.gen_training_data()

cgp.run_training_with_torchnn('one_neuron', training_data)             ## (A)   REMEMBER to also change learning_rate above

#training_iterations=40000, batch_size=8, learning_rate=1e-6
#equivalent to running multi_neuron_classifier.py
cgp = ComputationalGraphPrimerBatchDiv(
               num_layers = 3,
               layers_config = [4,2,1],                         # num of nodes in each layer
               expressions = ['xw=ap*xp+aq*xq+ar*xr+as*xs',
                              'xz=bp*xp+bq*xq+br*xr+bs*xs',
                              'xo=cp*xw+cq*xz'],
               output_vars = ['xo'],
               dataset_size = 5000,
               learning_rate = 1e-6,
               training_iterations = 40000,
               batch_size = 8,
               display_loss_how_often = 100,
               debug = True,
      )

cgp.parse_multi_layer_expressions()

cgp.display_multi_neuron_network()

training_data = cgp.gen_training_data()

cgp.run_training_loop_multi_neuron_model( training_data )

#equivalent to running verify_with_torchnn.py for multi_neuron_model
#set for multi neuron model, with same parameters as that for multi_neuron_classifier.py as above

cgp = ComputationalGraphPrimer(
               for_verification_only=True,
               num_layers = 3,
               layers_config = [4,2,1],                         # num of nodes in each layer
               expressions = ['xw=ap*xp+aq*xq+ar*xr+as*xs',
                              'xz=bp*xp+bq*xq+br*xr+bs*xs',
                              'xo=cp*xw+cq*xz'],
               output_vars = ['xo'],
               dataset_size = 5000,
               learning_rate = 1e-6,
               training_iterations = 40000,
               batch_size = 8,
               display_loss_how_often = 100,
               debug = True,
      )
##  This call is needed for generating the training data:
cgp.parse_expressions()

training_data = cgp.gen_training_data()

cgp.run_training_with_torchnn('multi_neuron', training_data)            ## (B)   REMEMBER to also change learning_rate above

class ComputationalGraphPrimerSGDPlus(ComputationalGraphPrimer):
  def __init__(self, *args, **kwargs):
    super(ComputationalGraphPrimerSGDPlus, self).__init__(*args, **kwargs)
    ######################################################################################################
    ######################################### one neuron model ###########################################
  def run_training_loop_one_neuron_model(self, training_data, mu):
      """
      The training loop must first initialize the learnable parameters.  Remember, these are the
      symbolic names in your input expressions for the neural layer that do not begin with the
      letter 'x'.  In this case, we are initializing with random numbers from a uniform distribution
      over the interval (0,1).
      """
      self.vals_for_learnable_params = {param: random.uniform(0,1) for param in self.learnable_params}

      self.bias = random.uniform(0,1)                   ## Adding the bias improves class discrimination.
                                                        ##   We initialize it to a random number.
      ################################## Source Code Modification Start ####################################
      ## Initialize v_t and mu for SGD with momentum for single-layer model
      self.mu = mu
      self.v_weights = {param: 0.0 for param in self.learnable_params}
      self.v_bias = 0.0
      ################################## Source Code Modification End ####################################

      class DataLoader:
          """
          To understand the logic of the dataloader, it would help if you first understand how
          the training dataset is created.  Search for the following function in this file:

                            gen_training_data(self)

          As you will see in the implementation code for this method, the training dataset
          consists of a Python dict with two keys, 0 and 1, the former points to a list of
          all Class 0 samples and the latter to a list of all Class 1 samples.  In each list,
          the data samples are drawn from a multi-dimensional Gaussian distribution.  The two
          classes have different means and variances.  The dimensionality of each data sample
          is set by the number of nodes in the input layer of the neural network.

          The data loader's job is to construct a batch of samples drawn randomly from the two
          lists mentioned above.  And it mush also associate the class label with each sample
          separately.
          """
          def __init__(self, training_data, batch_size):
              self.training_data = training_data
              self.batch_size = batch_size
              self.class_0_samples = [(item, 0) for item in self.training_data[0]]   ## Associate label 0 with each sample
              self.class_1_samples = [(item, 1) for item in self.training_data[1]]   ## Associate label 1 with each sample

          def __len__(self):
              return len(self.training_data[0]) + len(self.training_data[1])

          def _getitem(self):
              cointoss = random.choice([0,1])                            ## When a batch is created by getbatch(), we want the
                                                                          ##   samples to be chosen randomly from the two lists
              if cointoss == 0:
                  return random.choice(self.class_0_samples)
              else:
                  return random.choice(self.class_1_samples)

          def getbatch(self):
              batch_data,batch_labels = [],[]                            ## First list for samples, the second for labels
              maxval = 0.0                                               ## For approximate batch data normalization
              for _ in range(self.batch_size):
                  item = self._getitem()
                  if np.max(item[0]) > maxval:
                      maxval = np.max(item[0])
                  batch_data.append(item[0])
                  batch_labels.append(item[1])
              batch_data = [item/maxval for item in batch_data]          ## Normalize batch data
              batch = [batch_data, batch_labels]
              return batch


      data_loader = DataLoader(training_data, batch_size=self.batch_size)
      loss_running_record = []
      i = 0
      avg_loss_over_iterations = 0.0                                    ##  Average the loss over iterations for printing out
                                                                          ##    every N iterations during the training loop.
      for i in range(self.training_iterations):
          data = data_loader.getbatch()
          data_tuples_in_batch = data[0]
          class_labels_in_batch = data[1]
          y_preds, deriv_sigmoids =  self.forward_prop_one_neuron_model(data_tuples_in_batch)     ##  FORWARD PROP of data
          loss = sum([(abs(class_labels_in_batch[i] - y_preds[i]))**2 for i in range(len(class_labels_in_batch))])  ##  Find loss
          avg_loss_over_iterations += loss / float(len(class_labels_in_batch))
          if i%(self.display_loss_how_often) == 0:
              avg_loss_over_iterations /= self.display_loss_how_often
              loss_running_record.append(avg_loss_over_iterations)
              print("[iter=%d]  loss = %.4f" %  (i+1, avg_loss_over_iterations))                 ## Display average loss
              avg_loss_over_iterations = 0.0                                                     ## Re-initialize avg loss
          y_errors_in_batch = list(map(operator.sub, class_labels_in_batch, y_preds))
          self.backprop_and_update_params_one_neuron_model(data_tuples_in_batch, y_preds, y_errors_in_batch, deriv_sigmoids)  ## BACKPROP loss
      plt.figure()
      plt.plot(loss_running_record)
      plt.show()

  def backprop_and_update_params_one_neuron_model(self, data_tuples_in_batch, predictions, y_errors_in_batch, deriv_sigmoids):
      """
      This function implements the equations shown on Slide 61 of my Week 3 presentation in our DL
      class at Purdue.  All four parameters defined above are lists of what was either supplied to the
      forward prop function or calculated by it for each training data sample in a batch.
      """
      input_vars = self.independent_vars
      input_vars_to_param_map = self.var_to_var_param[self.output_vars[0]]                  ## These two statements align the
      param_to_vars_map = {param : var for var, param in input_vars_to_param_map.items()}   ##   the input vars
      vals_for_learnable_params = self.vals_for_learnable_params
      for i,param in enumerate(self.vals_for_learnable_params):
          ## For each param, sum the partials from every training data sample in batch
          partial_of_loss_wrt_param = 0.0
          ################################## Source Code Modification Start ####################################
          for j in range(self.batch_size):
              vals_for_input_vars_dict =  dict(zip(input_vars, list(data_tuples_in_batch[j])))
              partial_of_loss_wrt_param   +=   -  y_errors_in_batch[j] * vals_for_input_vars_dict[param_to_vars_map[param]] * deriv_sigmoids[j]

          # Average partial derivatives across the batch
          partial_of_loss_wrt_param /= float(self.batch_size)
          self.v_weights[param] = self.mu * self.v_weights[param] + self.learning_rate * partial_of_loss_wrt_param

          step = self.v_weights[param]
          ## Update the learnable parameters
          self.vals_for_learnable_params[param] += step
      y_error_avg = sum(y_errors_in_batch) / float(self.batch_size)
      deriv_sigmoid_avg = sum(deriv_sigmoids) / float(self.batch_size)

      ## Calculate v_(t+1) for bias
      self.v_bias = self.mu * self.v_bias + self.learning_rate * y_error_avg * deriv_sigmoid_avg
      self.bias += self.v_bias   ## Update the bias
    ################################## Source Code Modification End ####################################

  ######################################################################################################

  ######################################################################################################
  ######################################## multi neuron model ##########################################
  def run_training_loop_multi_neuron_model(self, training_data,mu):

      class DataLoader:
          """
          To understand the logic of the dataloader, it would help if you first understand how
          the training dataset is created.  Search for the following function in this file:

                            gen_training_data(self)

          As you will see in the implementation code for this method, the training dataset
          consists of a Python dict with two keys, 0 and 1, the former points to a list of
          all Class 0 samples and the latter to a list of all Class 1 samples.  In each list,
          the data samples are drawn from a multi-dimensional Gaussian distribution.  The two
          classes have different means and variances.  The dimensionality of each data sample
          is set by the number of nodes in the input layer of the neural network.

          The data loader's job is to construct a batch of samples drawn randomly from the two
          lists mentioned above.  And it mush also associate the class label with each sample
          separately.
          """
          def __init__(self, training_data, batch_size):
              self.training_data = training_data
              self.batch_size = batch_size
              self.class_0_samples = [(item, 0) for item in self.training_data[0]]    ## Associate label 0 with each sample
              self.class_1_samples = [(item, 1) for item in self.training_data[1]]    ## Associate label 1 with each sample

          def __len__(self):
              return len(self.training_data[0]) + len(self.training_data[1])

          def _getitem(self):
              cointoss = random.choice([0,1])                            ## When a batch is created by getbatch(), we want the
                                                                          ##   samples to be chosen randomly from the two lists
              if cointoss == 0:
                  return random.choice(self.class_0_samples)
              else:
                  return random.choice(self.class_1_samples)

          def getbatch(self):
              batch_data,batch_labels = [],[]                            ## First list for samples, the second for labels
              maxval = 0.0                                               ## For approximate batch data normalization
              for _ in range(self.batch_size):
                  item = self._getitem()
                  if np.max(item[0]) > maxval:
                      maxval = np.max(item[0])
                  batch_data.append(item[0])
                  batch_labels.append(item[1])
              batch_data = [item/maxval for item in batch_data]          ## Normalize batch data
              batch = [batch_data, batch_labels]
              return batch

      ##  The training loop must first initialize the learnable parameters.  Remember, these are the
      ##  symbolic names in your input expressions for the neural layer that do not begin with the
      ##  letter 'x'.  In this case, we are initializing with random numbers from a uniform distribution
      ##  over the interval (0,1):
      self.vals_for_learnable_params = {param: random.uniform(0,1) for param in self.learnable_params}
      ##  In the same  manner, we must also initialize the biases at each node that aggregates forward
      ##  propagating data:
      self.bias =   {i : [random.uniform(0,1) for j in range( self.layers_config[i] ) ]  for i in range(1, self.num_layers)}
      ################################## Source Code Modification Start ####################################
      ## Initialize v_t and mu for SGD with momentum for multi-layer model
      self.mu = mu
      self.v_weights = {param: 0.0 for param in self.learnable_params}
      self.v_bias = {i : [0.0 for j in range( self.layers_config[i] ) ]  for i in range(1, self.num_layers)}

      ################################## Source Code Modification End ####################################
      data_loader = DataLoader(training_data, batch_size=self.batch_size)
      loss_running_record = []
      i = 0
      avg_loss_over_iterations = 0.0                                          ##  Average the loss over iterations for printing out
                                                                              ##    every N iterations during the training loop.
      for i in range(self.training_iterations):
          data = data_loader.getbatch()
          data_tuples = data[0]
          class_labels = data[1]
          self.forward_prop_multi_neuron_model(data_tuples)                                       ## FORW PROP works by side-effect
          predicted_labels_for_batch = self.forw_prop_vals_at_layers[self.num_layers-1]           ## Predictions from FORW PROP
          y_preds =  [item for sublist in  predicted_labels_for_batch  for item in sublist]       ## Get numeric vals for predictions
          loss = sum([(abs(class_labels[i] - y_preds[i]))**2 for i in range(len(class_labels))])  ## Calculate loss for batch
          loss_avg = loss / float(len(class_labels))                                              ## Average the loss over batch
          avg_loss_over_iterations += loss_avg                                                    ## Add to Average loss over iterations
          if i%(self.display_loss_how_often) == 0:
              avg_loss_over_iterations /= self.display_loss_how_often
              loss_running_record.append(avg_loss_over_iterations)
              print("[iter=%d]  loss = %.4f" %  (i+1, avg_loss_over_iterations))                  ## Display avg loss
              avg_loss_over_iterations = 0.0                                                      ## Re-initialize avg-over-iterations loss
          y_errors_in_batch = list(map(operator.sub, class_labels, y_preds))
          self.backprop_and_update_params_multi_neuron_model(y_preds, y_errors_in_batch)
      plt.figure()
      plt.plot(loss_running_record)
      plt.show()

  def backprop_and_update_params_multi_neuron_model(self, predictions, y_errors):
      """
      First note that loop index variable 'back_layer_index' starts with the index of
      the last layer.  For the 3-layer example shown for 'forward', back_layer_index
      starts with a value of 2, its next value is 1, and that's it.

      In the code below, the outermost loop is over the data samples in a batch. As shown
      on Slide 73 of my Week 3 lecture, in order to calculate the partials of Loss with
      respect to the learnable params, we need to backprop the prediction errors and
      the gradients of the Sigmoid.  For the purpose of satisfying the requirements of
      SGD, the backprop of the prediction errors and the gradients needs to be carried
      out separately for each training data sample in a batch.  That's what the outer
      loop is for.

      After we exit the outermost loop, we average over the results obtained from each
      training data sample in a batch.

      Pay attention to the variable 'vars_in_layer'.  These store the node variables in
      the current layer during backpropagation.
      """
      ## Eq. (24) on Slide 73 of my Week 3 lecture says we need to store backproped errors in each layer leading up to the last:
      pred_err_backproped_at_layers =   [ {i : [None for j in range( self.layers_config[i] ) ]
                                                                for i in range(self.num_layers)} for _ in range(self.batch_size) ]
      ## This will store "\delta L / \delta w" you see at the LHS of the equations on Slide 73:
      partial_of_loss_wrt_params = {param : 0.0 for param in self.all_params}
      ## For estimating the changes to the bias to be made on the basis of the derivatives of the Sigmoids:
      bias_changes =   {i : [0.0 for j in range( self.layers_config[i] ) ]  for i in range(1, self.num_layers)}
      for b in range(self.batch_size):
          pred_err_backproped_at_layers[b][self.num_layers - 1] = [ y_errors[b] ]
          for back_layer_index in reversed(range(1,self.num_layers)):             ## For the 3-layer network, the first val for back_layer_index is 2 for the 3rd layer
              input_vals = self.forw_prop_vals_at_layers[back_layer_index -1]     ## This is a list of 8 two-element lists  --- since we have two nodes in the 2nd layer
              deriv_sigmoids =  self.gradient_vals_for_layers[back_layer_index]   ## This is a list eight one-element lists, one for each batch element
              vars_in_layer  =  self.layer_vars[back_layer_index]                 ## A list like ['xo']
              vars_in_next_layer_back  =  self.layer_vars[back_layer_index - 1]   ## A list like ['xw', 'xz']
              vals_for_input_vars_dict =  dict(zip(vars_in_next_layer_back, self.forw_prop_vals_at_layers[back_layer_index - 1][b]))
              ## For the next statement, note that layer_params are stored in a dict like
              ##       {1: [['ap', 'aq', 'ar', 'as'], ['bp', 'bq', 'br', 'bs']], 2: [['cp', 'cq']]}
              ## "layer_params[idx]" is a list of lists for the link weights in layer whose output nodes are in layer "idx"
              layer_params = self.layer_params[back_layer_index]
              transposed_layer_params = list(zip(*layer_params))                  ## Creating a transpose of the link matrix, See Eq. 30 on Slide 77
              for k,var1 in enumerate(vars_in_next_layer_back):
                  for j,var2 in enumerate(vars_in_layer):
                      pred_err_backproped_at_layers[b][back_layer_index - 1][k] = sum([self.vals_for_learnable_params[transposed_layer_params[k][i]]
                                                                                      * pred_err_backproped_at_layers[b][back_layer_index][i]
                                                                                                                for i in range(len(vars_in_layer))])
              for j,var in enumerate(vars_in_layer):
                  layer_params = self.layer_params[back_layer_index][j]           ##  ['cp', 'cq']   for the end layer
                  input_vars_to_param_map = self.var_to_var_param[var]            ## These two statements align the    {'xw': 'cp', 'xz': 'cq'}
                  param_to_vars_map = {param : var for var, param in input_vars_to_param_map.items()}   ##   and the input vars   {'cp': 'xw', 'cq': 'xz'}

                  ##  Update the partials of Loss wrt to the learnable parameters between the current layer
                  ##  and the previous layer. You are accumulating these partials over the different training
                  ##  data samples in the batch being processed.  For each training data sample, the formula
                  ##  being used is shown in Eq. (29) on Slide 77 of my Week 3 slides:
                  for i,param in enumerate(layer_params):
                      partial_of_loss_wrt_params[param]   +=   pred_err_backproped_at_layers[b][back_layer_index][j] * \
                                                                      vals_for_input_vars_dict[param_to_vars_map[param]] * deriv_sigmoids[b][j]
              ##  We will now estimate the change in the bias that needs to be made at each node in the previous layer
              ##  from the derivatives the sigmoid at the nodes in the current layer and the prediction error as
              ##  backproped to the previous layer nodes:
              for k,var1 in enumerate(vars_in_next_layer_back):
                  for j,var2 in enumerate(vars_in_layer):
                      if back_layer_index-1 > 0:
                          bias_changes[back_layer_index-1][k] += pred_err_backproped_at_layers[b][back_layer_index - 1][k] * deriv_sigmoids[b][j]

  ################################## Source Code Modification Start ####################################
      ## Now update the learnable parameters.  The loop shown below carries out SGD mandated averaging
      for param in partial_of_loss_wrt_params:
          partial_of_loss_wrt_param = partial_of_loss_wrt_params[param] /  float(self.batch_size)
          self.v_weights[param] = self.mu * self.v_weights[param] + self.learning_rate * partial_of_loss_wrt_param
          step = self.v_weights[param]
          self.vals_for_learnable_params[param] += step

      ##  Finally we update the biases at all the nodes that aggregate data:
      for layer_index in range(1,self.num_layers):
          for k in range(self.layers_config[layer_index]):
              self.v_bias[layer_index][k] = self.mu * self.v_bias[layer_index][k] + self.learning_rate * ( bias_changes[layer_index][k] / float(self.batch_size) )
              self.bias[layer_index][k]  +=  self.v_bias[layer_index][k]

  ################################## Source Code Modification End ####################################

  ######################################################################################################

class ComputationalGraphPrimerAdam(ComputationalGraphPrimer):
  def __init__(self, *args, **kwargs):
    super(ComputationalGraphPrimerAdam, self).__init__(*args, **kwargs)
    ######################################################################################################
    ######################################### one neuron model ###########################################
  def run_training_loop_one_neuron_model(self, training_data, beta_1, beta_2, eps):
      """
      The training loop must first initialize the learnable parameters.  Remember, these are the
      symbolic names in your input expressions for the neural layer that do not begin with the
      letter 'x'.  In this case, we are initializing with random numbers from a uniform distribution
      over the interval (0,1).
      """
      self.vals_for_learnable_params = {param: random.uniform(0,1) for param in self.learnable_params}

      self.bias = random.uniform(0,1)                   ## Adding the bias improves class discrimination.
                                                        ##   We initialize it to a random number.
      ################################## Source Code Modification Start ####################################
      ## Initialize m_t, v_t, beta_1, beta_2 and epsilon for Adam for single-layer model
      self.beta_1 = beta_1
      self.beta_2 = beta_2
      self.eps = eps

      self.v_weights = {param: 0.0 for param in self.learnable_params}
      self.v_bias = 0.0
      self.m_weights = {param: 0.0 for param in self.learnable_params}
      self.m_bias = 0.0

      ################################## Source Code Modification End ####################################

      class DataLoader:
          """
          To understand the logic of the dataloader, it would help if you first understand how
          the training dataset is created.  Search for the following function in this file:

                            gen_training_data(self)

          As you will see in the implementation code for this method, the training dataset
          consists of a Python dict with two keys, 0 and 1, the former points to a list of
          all Class 0 samples and the latter to a list of all Class 1 samples.  In each list,
          the data samples are drawn from a multi-dimensional Gaussian distribution.  The two
          classes have different means and variances.  The dimensionality of each data sample
          is set by the number of nodes in the input layer of the neural network.

          The data loader's job is to construct a batch of samples drawn randomly from the two
          lists mentioned above.  And it mush also associate the class label with each sample
          separately.
          """
          def __init__(self, training_data, batch_size):
              self.training_data = training_data
              self.batch_size = batch_size
              self.class_0_samples = [(item, 0) for item in self.training_data[0]]   ## Associate label 0 with each sample
              self.class_1_samples = [(item, 1) for item in self.training_data[1]]   ## Associate label 1 with each sample

          def __len__(self):
              return len(self.training_data[0]) + len(self.training_data[1])

          def _getitem(self):
              cointoss = random.choice([0,1])                            ## When a batch is created by getbatch(), we want the
                                                                          ##   samples to be chosen randomly from the two lists
              if cointoss == 0:
                  return random.choice(self.class_0_samples)
              else:
                  return random.choice(self.class_1_samples)

          def getbatch(self):
              batch_data,batch_labels = [],[]                            ## First list for samples, the second for labels
              maxval = 0.0                                               ## For approximate batch data normalization
              for _ in range(self.batch_size):
                  item = self._getitem()
                  if np.max(item[0]) > maxval:
                      maxval = np.max(item[0])
                  batch_data.append(item[0])
                  batch_labels.append(item[1])
              batch_data = [item/maxval for item in batch_data]          ## Normalize batch data
              batch = [batch_data, batch_labels]
              return batch


      data_loader = DataLoader(training_data, batch_size=self.batch_size)
      loss_running_record = []
      i = 0
      avg_loss_over_iterations = 0.0                                    ##  Average the loss over iterations for printing out
                                                                          ##    every N iterations during the training loop.
      for i in range(self.training_iterations):
          data = data_loader.getbatch()
          data_tuples_in_batch = data[0]
          class_labels_in_batch = data[1]
          y_preds, deriv_sigmoids =  self.forward_prop_one_neuron_model(data_tuples_in_batch)     ##  FORWARD PROP of data
          loss = sum([(abs(class_labels_in_batch[i] - y_preds[i]))**2 for i in range(len(class_labels_in_batch))])  ##  Find loss
          avg_loss_over_iterations += loss / float(len(class_labels_in_batch))
          if i%(self.display_loss_how_often) == 0:
              avg_loss_over_iterations /= self.display_loss_how_often
              loss_running_record.append(avg_loss_over_iterations)
              print("[iter=%d]  loss = %.4f" %  (i+1, avg_loss_over_iterations))                 ## Display average loss
              avg_loss_over_iterations = 0.0                                                     ## Re-initialize avg loss
          y_errors_in_batch = list(map(operator.sub, class_labels_in_batch, y_preds))
          self.backprop_and_update_params_one_neuron_model(data_tuples_in_batch, y_preds, y_errors_in_batch, deriv_sigmoids,i+1)  ## BACKPROP loss
      plt.figure()
      plt.plot(loss_running_record)
      plt.show()

  def backprop_and_update_params_one_neuron_model(self, data_tuples_in_batch, predictions, y_errors_in_batch, deriv_sigmoids,iter):
      """
      This function implements the equations shown on Slide 61 of my Week 3 presentation in our DL
      class at Purdue.  All four parameters defined above are lists of what was either supplied to the
      forward prop function or calculated by it for each training data sample in a batch.
      """
      input_vars = self.independent_vars
      input_vars_to_param_map = self.var_to_var_param[self.output_vars[0]]                  ## These two statements align the
      param_to_vars_map = {param : var for var, param in input_vars_to_param_map.items()}   ##   the input vars
      vals_for_learnable_params = self.vals_for_learnable_params
      for i,param in enumerate(self.vals_for_learnable_params):
          ## For each param, sum the partials from every training data sample in batch
          partial_of_loss_wrt_param = 0.0
          for j in range(self.batch_size):
        ################################## Source Code Modification Start ####################################
              vals_for_input_vars_dict =  dict(zip(input_vars, list(data_tuples_in_batch[j])))
              partial_of_loss_wrt_param   +=   -  y_errors_in_batch[j] * vals_for_input_vars_dict[param_to_vars_map[param]] * deriv_sigmoids[j]

          partial_of_loss_wrt_param /=  float(self.batch_size)
          self.m_weights[param] = self.beta_1 * self.m_weights[param] + (1 - self.beta_1) * partial_of_loss_wrt_param
          self.v_weights[param] = self.beta_2 * self.v_weights[param] + (1 - self.beta_2) * partial_of_loss_wrt_param**2

          ## Apply bias correction
          m_corrected = self.m_weights[param] / (1 - self.beta_1**iter)
          v_corrected = self.v_weights[param] / (1 - self.beta_2**iter)
          step = self.learning_rate* (m_corrected / (np.sqrt(v_corrected) + self.eps))
          ## Update the learnable parameters
          self.vals_for_learnable_params[param] += step

      ## Calculate gradient update, m_(t+1) and v_(t+1) for bias
      y_error_avg = sum(y_errors_in_batch) / float(self.batch_size)
      deriv_sigmoid_avg = sum(deriv_sigmoids) / float(self.batch_size)

      self.m_bias = self.beta_1 * self.m_bias + (1 - self.beta_1) * (y_error_avg * deriv_sigmoid_avg)
      self.v_bias = self.beta_2 * self.v_bias + (1 - self.beta_2) * (y_error_avg * deriv_sigmoid_avg)**2

      ## Apply bias correction
      m_corrected = self.m_bias / (1 - self.beta_1**iter)
      v_corrected = self.v_bias / (1 - self.beta_2**iter)

      ## Update the bias
      self.bias += self.learning_rate * (m_corrected/np.sqrt(v_corrected + self.eps))
      ################################## Source Code Modification End ####################################

  ######################################################################################################

  ######################################################################################################
  ######################################## multi neuron model ##########################################
  def run_training_loop_multi_neuron_model(self, training_data,beta_1, beta_2, eps):

      class DataLoader:
          """
          To understand the logic of the dataloader, it would help if you first understand how
          the training dataset is created.  Search for the following function in this file:

                            gen_training_data(self)

          As you will see in the implementation code for this method, the training dataset
          consists of a Python dict with two keys, 0 and 1, the former points to a list of
          all Class 0 samples and the latter to a list of all Class 1 samples.  In each list,
          the data samples are drawn from a multi-dimensional Gaussian distribution.  The two
          classes have different means and variances.  The dimensionality of each data sample
          is set by the number of nodes in the input layer of the neural network.

          The data loader's job is to construct a batch of samples drawn randomly from the two
          lists mentioned above.  And it mush also associate the class label with each sample
          separately.
          """
          def __init__(self, training_data, batch_size):
              self.training_data = training_data
              self.batch_size = batch_size
              self.class_0_samples = [(item, 0) for item in self.training_data[0]]    ## Associate label 0 with each sample
              self.class_1_samples = [(item, 1) for item in self.training_data[1]]    ## Associate label 1 with each sample

          def __len__(self):
              return len(self.training_data[0]) + len(self.training_data[1])

          def _getitem(self):
              cointoss = random.choice([0,1])                            ## When a batch is created by getbatch(), we want the
                                                                          ##   samples to be chosen randomly from the two lists
              if cointoss == 0:
                  return random.choice(self.class_0_samples)
              else:
                  return random.choice(self.class_1_samples)

          def getbatch(self):
              batch_data,batch_labels = [],[]                            ## First list for samples, the second for labels
              maxval = 0.0                                               ## For approximate batch data normalization
              for _ in range(self.batch_size):
                  item = self._getitem()
                  if np.max(item[0]) > maxval:
                      maxval = np.max(item[0])
                  batch_data.append(item[0])
                  batch_labels.append(item[1])
              batch_data = [item/maxval for item in batch_data]          ## Normalize batch data
              batch = [batch_data, batch_labels]
              return batch

      ##  The training loop must first initialize the learnable parameters.  Remember, these are the
      ##  symbolic names in your input expressions for the neural layer that do not begin with the
      ##  letter 'x'.  In this case, we are initializing with random numbers from a uniform distribution
      ##  over the interval (0,1):
      self.vals_for_learnable_params = {param: random.uniform(0,1) for param in self.learnable_params}
      ##  In the same  manner, we must also initialize the biases at each node that aggregates forward
      ##  propagating data:
      self.bias =   {i : [random.uniform(0,1) for j in range( self.layers_config[i] ) ]  for i in range(1, self.num_layers)}
      ################################## Source Code Modification Start ####################################
      ## Initialize m_t, v_t, beta_1, beta_2 and epsilon for Adam for multi-layer model
      self.beta_1 = beta_1
      self.beta_2 = beta_2
      self.eps = eps

      self.v_weights = {param: 0.0 for param in self.learnable_params}
      self.v_bias = {i: [0.0 for j in range(self.layers_config[i])] for i in range(1, self.num_layers)}
      self.m_weights = {param: 0.0 for param in self.learnable_params}
      self.m_bias = {i: [0.0 for j in range(self.layers_config[i])] for i in range(1, self.num_layers)}


      ################################## Source Code Modification End ####################################
      data_loader = DataLoader(training_data, batch_size=self.batch_size)
      loss_running_record = []
      i = 0
      avg_loss_over_iterations = 0.0                                          ##  Average the loss over iterations for printing out
                                                                              ##    every N iterations during the training loop.
      for i in range(self.training_iterations):
          data = data_loader.getbatch()
          data_tuples = data[0]
          class_labels = data[1]
          self.forward_prop_multi_neuron_model(data_tuples)                                       ## FORW PROP works by side-effect
          predicted_labels_for_batch = self.forw_prop_vals_at_layers[self.num_layers-1]           ## Predictions from FORW PROP
          y_preds =  [item for sublist in  predicted_labels_for_batch  for item in sublist]       ## Get numeric vals for predictions
          loss = sum([(abs(class_labels[i] - y_preds[i]))**2 for i in range(len(class_labels))])  ## Calculate loss for batch
          loss_avg = loss / float(len(class_labels))                                              ## Average the loss over batch
          avg_loss_over_iterations += loss_avg                                                    ## Add to Average loss over iterations
          if i%(self.display_loss_how_often) == 0:
              avg_loss_over_iterations /= self.display_loss_how_often
              loss_running_record.append(avg_loss_over_iterations)
              print("[iter=%d]  loss = %.4f" %  (i+1, avg_loss_over_iterations))                  ## Display avg loss
              avg_loss_over_iterations = 0.0                                                      ## Re-initialize avg-over-iterations loss
          y_errors_in_batch = list(map(operator.sub, class_labels, y_preds))
          self.backprop_and_update_params_multi_neuron_model(y_preds, y_errors_in_batch,i+1)
      plt.figure()
      plt.plot(loss_running_record)
      plt.show()

  def backprop_and_update_params_multi_neuron_model(self, predictions, y_errors,iter):
      """
      First note that loop index variable 'back_layer_index' starts with the index of
      the last layer.  For the 3-layer example shown for 'forward', back_layer_index
      starts with a value of 2, its next value is 1, and that's it.

      In the code below, the outermost loop is over the data samples in a batch. As shown
      on Slide 73 of my Week 3 lecture, in order to calculate the partials of Loss with
      respect to the learnable params, we need to backprop the prediction errors and
      the gradients of the Sigmoid.  For the purpose of satisfying the requirements of
      SGD, the backprop of the prediction errors and the gradients needs to be carried
      out separately for each training data sample in a batch.  That's what the outer
      loop is for.

      After we exit the outermost loop, we average over the results obtained from each
      training data sample in a batch.

      Pay attention to the variable 'vars_in_layer'.  These store the node variables in
      the current layer during backpropagation.
      """
      ## Eq. (24) on Slide 73 of my Week 3 lecture says we need to store backproped errors in each layer leading up to the last:
      pred_err_backproped_at_layers =   [ {i : [None for j in range( self.layers_config[i] ) ]
                                                                for i in range(self.num_layers)} for _ in range(self.batch_size) ]
      ## This will store "\delta L / \delta w" you see at the LHS of the equations on Slide 73:
      partial_of_loss_wrt_params = {param : 0.0 for param in self.all_params}
      ## For estimating the changes to the bias to be made on the basis of the derivatives of the Sigmoids:
      bias_changes =   {i : [0.0 for j in range( self.layers_config[i] ) ]  for i in range(1, self.num_layers)}
      for b in range(self.batch_size):
          pred_err_backproped_at_layers[b][self.num_layers - 1] = [ y_errors[b] ]
          for back_layer_index in reversed(range(1,self.num_layers)):             ## For the 3-layer network, the first val for back_layer_index is 2 for the 3rd layer
              input_vals = self.forw_prop_vals_at_layers[back_layer_index -1]     ## This is a list of 8 two-element lists  --- since we have two nodes in the 2nd layer
              deriv_sigmoids =  self.gradient_vals_for_layers[back_layer_index]   ## This is a list eight one-element lists, one for each batch element
              vars_in_layer  =  self.layer_vars[back_layer_index]                 ## A list like ['xo']
              vars_in_next_layer_back  =  self.layer_vars[back_layer_index - 1]   ## A list like ['xw', 'xz']
              vals_for_input_vars_dict =  dict(zip(vars_in_next_layer_back, self.forw_prop_vals_at_layers[back_layer_index - 1][b]))
              ## For the next statement, note that layer_params are stored in a dict like
              ##       {1: [['ap', 'aq', 'ar', 'as'], ['bp', 'bq', 'br', 'bs']], 2: [['cp', 'cq']]}
              ## "layer_params[idx]" is a list of lists for the link weights in layer whose output nodes are in layer "idx"
              layer_params = self.layer_params[back_layer_index]
              transposed_layer_params = list(zip(*layer_params))                  ## Creating a transpose of the link matrix, See Eq. 30 on Slide 77
              for k,var1 in enumerate(vars_in_next_layer_back):
                  for j,var2 in enumerate(vars_in_layer):
                      pred_err_backproped_at_layers[b][back_layer_index - 1][k] = sum([self.vals_for_learnable_params[transposed_layer_params[k][i]]
                                                                                      * pred_err_backproped_at_layers[b][back_layer_index][i]
                                                                                                                for i in range(len(vars_in_layer))])
              for j,var in enumerate(vars_in_layer):
                  layer_params = self.layer_params[back_layer_index][j]           ##  ['cp', 'cq']   for the end layer
                  input_vars_to_param_map = self.var_to_var_param[var]            ## These two statements align the    {'xw': 'cp', 'xz': 'cq'}
                  param_to_vars_map = {param : var for var, param in input_vars_to_param_map.items()}   ##   and the input vars   {'cp': 'xw', 'cq': 'xz'}

                  ##  Update the partials of Loss wrt to the learnable parameters between the current layer
                  ##  and the previous layer. You are accumulating these partials over the different training
                  ##  data samples in the batch being processed.  For each training data sample, the formula
                  ##  being used is shown in Eq. (29) on Slide 77 of my Week 3 slides:
                  for i,param in enumerate(layer_params):
                      partial_of_loss_wrt_params[param]   +=   pred_err_backproped_at_layers[b][back_layer_index][j] * \
                                                                      vals_for_input_vars_dict[param_to_vars_map[param]] * deriv_sigmoids[b][j]
              ##  We will now estimate the change in the bias that needs to be made at each node in the previous layer
              ##  from the derivatives the sigmoid at the nodes in the current layer and the prediction error as
              ##  backproped to the previous layer nodes:
              for k,var1 in enumerate(vars_in_next_layer_back):
                  for j,var2 in enumerate(vars_in_layer):
                      if back_layer_index-1 > 0:
                          bias_changes[back_layer_index-1][k] += pred_err_backproped_at_layers[b][back_layer_index - 1][k] * deriv_sigmoids[b][j]

      ## Now update the learnable parameters.  The loop shown below carries out SGD mandated averaging
      ################################## Source Code Modification Start ####################################
      for param in partial_of_loss_wrt_params:
          partial_of_loss_wrt_param = partial_of_loss_wrt_params[param] /  float(self.batch_size)
          self.m_weights[param] = self.beta_1 * self.m_weights[param] + (1 - self.beta_1) * partial_of_loss_wrt_param
          self.v_weights[param] = self.beta_2 * self.v_weights[param] + (1 - self.beta_2) * partial_of_loss_wrt_param**2

          ## Apply bias correction
          m_corrected = self.m_weights[param] / (1 - self.beta_1**iter)
          v_corrected = self.v_weights[param] / (1 - self.beta_2**iter)
          ## Calculate the next step in the parameter hyperplane
          step = self.learning_rate* (m_corrected / np.sqrt(v_corrected + self.eps))

          ## Update the learnable parameters
          self.vals_for_learnable_params[param] += step

      ##  Finally we update the biases at all the nodes that aggregate data:
      for layer_index in range(1,self.num_layers):
          for k in range(self.layers_config[layer_index]):
              self.m_bias[layer_index][k] = self.beta_1 * self.m_bias[layer_index][k] + (1 - self.beta_1)*( bias_changes[layer_index][k] / float(self.batch_size) )
              self.v_bias[layer_index][k] = self.beta_2 * self.v_bias[layer_index][k] + (1 - self.beta_2)*( bias_changes[layer_index][k] / float(self.batch_size) )**2

              ## Apply bias correction
              m_corrected = self.m_bias[layer_index][k] / (1 - self.beta_1**iter)
              v_corrected = self.v_bias[layer_index][k] / (1 - self.beta_2**iter)
              self.bias[layer_index][k]  +=  self.learning_rate * (m_corrected/np.sqrt(v_corrected + self.eps))
      ################################## Source Code Modification End ####################################
  ######################################################################################################

import io
import re
import sys

def get_loss_n_iter_values(learning_algo="SGD",one_neuron_model=True, num_layers=None, layers_config=1,expressions=['xw=ab*xa+bc*xb+cd*xc+ac*xd'], output_vars=['xw'], dataset_size=5000, learning_rate=1e-3, training_iterations=50000, batch_size=8, display_loss_how_often=100, debug=True):
  # Context manager for managing stdout redirection
  old_stdout = sys.stdout
  sys.stdout = mystdout = io.StringIO()

  if("SGD" == learning_algo):
    cgp = ComputationalGraphPrimerBatchDiv(
      one_neuron_model=one_neuron_model,
      num_layers = num_layers,
      layers_config = layers_config,
      expressions=expressions,
      output_vars=output_vars,
      dataset_size=dataset_size,
      learning_rate=learning_rate,
      training_iterations=training_iterations,
      batch_size=batch_size,
      display_loss_how_often=display_loss_how_often,
      debug=debug
    )
  elif("SGD+" == learning_algo):
    cgp = ComputationalGraphPrimerSGDPlus(
      one_neuron_model=one_neuron_model,
      num_layers = num_layers,
      layers_config = layers_config,
      expressions=expressions,
      output_vars=output_vars,
      dataset_size=dataset_size,
      learning_rate=learning_rate,
      training_iterations=training_iterations,
      batch_size=batch_size,
      display_loss_how_often=display_loss_how_often,
      debug=debug
    )
  else: #it is Adam
      cgp = ComputationalGraphPrimerAdam(
      one_neuron_model=one_neuron_model,
      num_layers = num_layers,
      layers_config = layers_config,
      expressions=expressions,
      output_vars=output_vars,
      dataset_size=dataset_size,
      learning_rate=learning_rate,
      training_iterations=training_iterations,
      batch_size=batch_size,
      display_loss_how_often=display_loss_how_often,
      debug=debug
    )

  if(one_neuron_model):
    cgp.parse_expressions()
    training_data = cgp.gen_training_data()
    if("SGD" == learning_algo):
      cgp.run_training_loop_one_neuron_model(training_data)
    elif("SGD+" == learning_algo):
      cgp.run_training_loop_one_neuron_model(training_data,0.9)
    else:
      cgp.run_training_loop_one_neuron_model(training_data,0.9, 0.99, 1e-8)

  else:
    cgp.parse_multi_layer_expressions()
    training_data = cgp.gen_training_data()
    if("SGD" == learning_algo):
      cgp.run_training_loop_multi_neuron_model(training_data)
    elif("SGD+" == learning_algo):
      cgp.run_training_loop_multi_neuron_model(training_data,0.9)
    else:
      cgp.run_training_loop_multi_neuron_model(training_data,0.9, 0.99, 1e-8)
  sys.stdout = old_stdout

  loss_str = mystdout.getvalue()
  loss_values = re.findall(r"loss = ([\d\.]+)", loss_str)
  loss_values = [float(value) for value in loss_values]
  iter_values = re.findall(r"iter=(\d+)", loss_str)
  iter_values = [int(value) for value in iter_values]

  return loss_values,iter_values
  # Plotting One Neuron Classifier Loss
#plot_loss(loss_values, iter_values, 'one_neuron_classifier', 'SGD', 0.001)

import matplotlib.pyplot as plt
def plot_loss(plot_title,*args):
    """
    Plots multiple loss curves with different variants on a single plot.

    Args:
        *args: A sequence of tuples, where each tuple contains (loss, iter, model_name, optimizer_name, learning_rate)
    """

    plt.figure(figsize=(10, 6))  # Set a larger figure size for better visibility

    for loss, iter, model_name, optimizer_name, learning_rate in args:
        plt.plot(iter, loss, label=f'{model_name} ({optimizer_name}, LR = {learning_rate})')

    plt.title(plot_title)
    plt.xlabel('Iterations') # Use iterations for plotting
    plt.ylabel('Loss')
    plt.grid(True) # Add gridlines for better readability
    plt.legend() # Show the legend for the loss curve

    plt.show()

learning_rates = [0.1,1,10];
learning_rates = [rate * 1e-3 for rate in learning_rates]
learning_algos = ["SGD","SGD+","ADAM"]
# Separate lists for loss and iteration values

for learning_rate in learning_rates:
  one_neuron_data = []
  multi_neuron_data = []
  for algo in  learning_algos:
    # One-neuron model
    loss_values_one_neuron, iter_values_one_neuron = get_loss_n_iter_values(learning_algo=algo,
        learning_rate=learning_rate
    )
    one_neuron_data.append((loss_values_one_neuron, iter_values_one_neuron, "one_neuron_model", algo, learning_rate))

    # Multi-neuron model
    loss_values_multi_neuron, iter_values_multi_neuron = get_loss_n_iter_values(learning_algo=algo,
        one_neuron_model=False,
        num_layers=3,
        layers_config=[4, 2, 1],
        expressions=['xw=ap*xp+aq*xq+ar*xr+as*xs',
                     'xz=bp*xp+bq*xq+br*xr+bs*xs',
                     'xo=cp*xw+cq*xz'],
        output_vars=['xo'],
        learning_rate=learning_rate
    )
    multi_neuron_data.append((loss_values_multi_neuron, iter_values_multi_neuron, "multi_neuron_model", algo, learning_rate))

  # Plot one-neuron curves
  plot_loss("One-Neuron Model Loss Curves",*one_neuron_data)

  # Plot multi-neuron curves
  plot_loss("Multi-Neuron Model Loss Curves",*multi_neuron_data)

import time
beta1_values = [0.7,0.9,0.99]
beta2_values = [0.8,0.9,0.99]
old_stdout = sys.stdout
results = []
for beta1 in beta1_values:
  for beta2 in beta1_values:
    sys.stdout = mystdout = io.StringIO()
    start_time = time.time()
    cgp = ComputationalGraphPrimerAdam(
    one_neuron_model=False,
    num_layers = 3,
    layers_config = [4,2,1],    # num of nodes in each layer
    expressions = ['xw=ap*xp+aq*xq+ar*xr+as*xs',
                    'xz=bp*xp+bq*xq+br*xr+bs*xs',
                    'xo=cp*xw+cq*xz'],
    output_vars=['xo'],
    dataset_size=5000,
    learning_rate=1e-3,
    training_iterations=50000,
    batch_size=8,
    display_loss_how_often=100,
    debug=True
    )
    cgp.parse_multi_layer_expressions()
    training_data = cgp.gen_training_data()
    cgp.run_training_loop_multi_neuron_model(training_data,beta1, beta2, 1e-8)
    end_time = time.time()
    elapsed_time = end_time - start_time
    sys.stdout = old_stdout
    loss_str = mystdout.getvalue()
    loss_values = re.findall(r"loss = ([\d\.]+)", loss_str)
    loss_values = [float(value) for value in loss_values]
    final_loss = loss_values[-1]
    min_loss = min(loss_values)
    results.append((beta1, beta2, elapsed_time, final_loss, min_loss))

# Create a clear and informative table
print("    |       Beta1       |       Beta2       | Time Taken (s) | Final Loss | Minimum Loss")
print("----|------------------|------------------|---------------|------------|-------------")
for i, (beta1, beta2, time_taken, final_loss, min_loss) in enumerate(results, start=1):
    print(f"{i:2d} | {beta1:14.2f} | {beta2:14.2f} | {time_taken:14.2f} | {final_loss:10.4f} | {min_loss:11.4f}")

#repeat with batch size 32
import time
beta1_values = [0.6,0.9,0.99]
beta2_values = [0.7,0.9,0.99]
old_stdout = sys.stdout
results = []
for beta1 in beta1_values:
  for beta2 in beta1_values:
    sys.stdout = mystdout = io.StringIO()
    start_time = time.time()
    cgp = ComputationalGraphPrimerAdam(
    one_neuron_model=False,
    num_layers = 3,
    layers_config = [4,2,1],    # num of nodes in each layer
    expressions = ['xw=ap*xp+aq*xq+ar*xr+as*xs',
                    'xz=bp*xp+bq*xq+br*xr+bs*xs',
                    'xo=cp*xw+cq*xz'],
    output_vars=['xo'],
    dataset_size=5000,
    learning_rate=1e-3,
    training_iterations=50000,
    batch_size=32,
    display_loss_how_often=100,
    debug=True
    )
    cgp.parse_multi_layer_expressions()
    training_data = cgp.gen_training_data()
    cgp.run_training_loop_multi_neuron_model(training_data,beta1, beta2, 1e-8)
    end_time = time.time()
    elapsed_time = end_time - start_time
    sys.stdout = old_stdout
    loss_str = mystdout.getvalue()
    loss_values = re.findall(r"loss = ([\d\.]+)", loss_str)
    loss_values = [float(value) for value in loss_values]
    final_loss = loss_values[-1]
    min_loss = min(loss_values)
    results.append((beta1, beta2, elapsed_time, final_loss, min_loss))

# Create a clear and informative table
print("    |       Beta1       |       Beta2       | Time Taken (s) | Final Loss | Minimum Loss")
print("----|------------------|------------------|---------------|------------|-------------")
for i, (beta1, beta2, time_taken, final_loss, min_loss) in enumerate(results, start=1):
    print(f"{i:2d} | {beta1:14.2f} | {beta2:14.2f} | {time_taken:14.2f} | {final_loss:10.4f} | {min_loss:11.4f}")