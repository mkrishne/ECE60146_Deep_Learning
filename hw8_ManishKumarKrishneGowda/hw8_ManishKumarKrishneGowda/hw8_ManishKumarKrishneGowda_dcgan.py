# -*- coding: utf-8 -*-
"""HW8_dcgan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1B5QiMJnh6WOfQ5BVGuKST3IdBihZoK2h
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/My Drive/hw8_data/

!wget -O DLStudio-2.4.3.tar.gz \
https://engineering.purdue.edu/kak/distDLS/DLStudio-2.4.3.tar.gz?download

#!tar -xvf DLStudio-2.4.3.tar.gz

# Commented out IPython magic to ensure Python compatibility.
#  %cd DLStudio-2.4.3

!pip install pymsgbox

!python setup.py install

!pip install pycocotools

!cd /content/drive/MyDrive/hw8_data/

import zipfile

# Specify the path to the zip file
zip_file_path = "/content/drive/My Drive/hw8_data/celeba_dataset_64x64.zip"

# Specify the directory to unzip the contents to
extract_to_dir = "/content/drive/MyDrive/hw8_data/celeba_dataset_64x64/"

# Unzip the file
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(extract_to_dir)

print("Extraction complete.")

import os

# List the contents of the extracted directory
extracted_files = os.listdir('/content/drive/MyDrive/hw8_data/celeba_dataset_64x64')
print("Extracted Files:")
print(len(extracted_files))

import os
import shutil

# Source directory
source_directory = '/content/drive/MyDrive/hw8_data/celeba_dataset_64x64/'

# Destination directory
destination_directory = os.path.join(source_directory, '0')

# Create the destination directory if it doesn't exist
if not os.path.exists(destination_directory):
    os.makedirs(destination_directory)

# List all files in the source directory
files = os.listdir(source_directory)

# Iterate over each file
for file in files:
    # Check if the file is an image file (you can adjust this condition based on your file extensions)
    if file.endswith('.jpg'):
        # Get the full path of the source file
        source_file_path = os.path.join(source_directory, file)

        # Move the file to the destination directory
        shutil.move(source_file_path, destination_directory)

print("Images moved to directory '0'.")

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/hw8_data/DLStudio-2.4.3
!pwd

!tar -xvf '/content/drive/MyDrive/hw8_data/DLStudio-2.4.3/datasets_for_AdversarialNetworks.tar.gz' -C "/content/drive/MyDrive/hw8_data/DLStudio-2.4.3/Examples"

!tar -xvf '/content/drive/MyDrive/hw8_data/DLStudio-2.4.3/Examples/dataGAN/PurdueShapes5GAN-20000.tar.gz' -C '/content/drive/MyDrive/hw8_data/DLStudio-2.4.3/Examples/dataGAN/'

import os
import torch
import random
import numpy as np
import requests
import matplotlib.pyplot as plt
from tqdm import tqdm
from PIL import Image

seed = 60146
random.seed(seed)
torch.manual_seed(seed)
torch.cuda.manual_seed(seed)
np.random.seed(seed)
torch.backends.cudnn.deterministic=True
torch.backends.cudnn.benchmarks=False
os.environ['PYTHONHASHSEED'] = str(seed)

##  watch -d -n 0.5 nvidia-smi

from DLStudio import *
from AdversarialLearning import *

import sys

dls = DLStudio(
                  dataroot = "/content/drive/MyDrive/hw8_data/celeba_dataset_64x64",
                  image_size = [64,64],
                  path_saved_model = "/content/drive/MyDrive/hw8_data/saved_models",
                  learning_rate = 1e-4,       ## <==  try smaller value if mode collapse
#                  learning_rate = 5e-3,      ## <==  try smaller value if mode collapse
                  epochs = 30,
                  batch_size = 32,
                  use_gpu = True,
              )

adversarial = AdversarialLearning(
                  dlstudio = dls,
                  ngpu = 1,
                  latent_vector_size = 100,
                  beta1 = 0.5,                           ## for the Adam optimizer
              )

dcgan =   AdversarialLearning.DataModeling( dlstudio = dls, adversarial = adversarial )


discriminator =  dcgan.DiscriminatorDG1()
generator =  dcgan.GeneratorDG1()

num_learnable_params_disc = sum(p.numel() for p in discriminator.parameters() if p.requires_grad)
print("\n\nThe number of learnable parameters in the Discriminator: %d\n" % num_learnable_params_disc)
num_learnable_params_gen = sum(p.numel() for p in generator.parameters() if p.requires_grad)
print("\nThe number of learnable parameters in the Generator: %d\n" % num_learnable_params_gen)
num_layers_disc = len(list(discriminator.parameters()))
print("\nThe number of layers in the discriminator: %d\n" % num_layers_disc)
num_layers_gen = len(list(generator.parameters()))
print("\nThe number of layers in the generator: %d\n\n" % num_layers_gen)

dcgan.set_dataloader()

print("\n\nHere is one batch of images from the training dataset:")
dcgan.show_sample_images_from_dataset(dls)

dcgan.run_gan_code(dls, adversarial, discriminator=discriminator, generator=generator, results_dir="results_DG1")

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print('Device:', device)

!pwd

generator2 = generator

# Path to save the generator's state dictionary
generator_state_dict_path = "/content/drive/MyDrive/hw8_data/saved_models/results_DG1generator.pt"

# Save the generator's state dictionary
torch.save(generator.state_dict(), generator_state_dict_path)

print("Generator's state dictionary saved at:", generator_state_dict_path)

import os
import torch
import torchvision

def generate_fake_images(generator, output_dir, num_images):
    """
    Generates fake images using the provided generator and saves them to the specified directory.

    Args:
        generator (torch.nn.Module): The generator model.
        output_dir (str): Directory path to save the fake images.
        num_images (int): Number of fake images to generate.
    """
    os.makedirs(output_dir, exist_ok=True)  # Ensure the output directory exists

    with torch.no_grad():
        for i in range(num_images):
            try:
                # Generate a random noise vector
                noise = torch.randn(1, 100, 1, 1, device=device)

                # Generate a fake image from the noise vector
                fake_image = generator(noise).detach().cpu()

                # Save the fake image
                fake_image_path = os.path.join(output_dir, f"fake_image_{i}.png")
                torchvision.utils.save_image(fake_image, fake_image_path)

                # Print progress
                if (i + 1) % 100 == 0:
                    print(f"Generated {i + 1} fake images.")

            except Exception as e:
                print(f"Error generating image {i + 1}: {str(e)}")

    print(f"All {num_images} fake images saved at: {output_dir}")

# Load the state dictionary of the generator
generator_state_dict = torch.load("/content/drive/MyDrive/hw8_data/saved_models/results_DG1generator.pt")
generator.load_state_dict(generator_state_dict)

# Define parameters
output_directory = "results_DG1/fake_images"
num_fake_images = 2048

# Generate and save fake images
generate_fake_images(generator, output_directory, num_fake_images)

!pip install pytorch-fid

import os
from pytorch_fid.fid_score import calculate_activation_statistics, calculate_frechet_distance
from pytorch_fid.inception import InceptionV3

# Define directories for real and fake images
fake_dir = "./results_DG1/fake_images/"
real_dir = "/content/drive/MyDrive/hw8_data/celeba_dataset_64x64/0/"

# Get the list of image files in the directories
real_image_paths = [os.path.join(real_dir, f) for f in os.listdir(real_dir) if os.path.isfile(os.path.join(real_dir, f))]
fake_image_paths = [os.path.join(fake_dir, f) for f in os.listdir(fake_dir) if os.path.isfile(os.path.join(fake_dir, f))]

# Specify the InceptionV3 model and dimensions
dims = 2048
block_idx = InceptionV3.BLOCK_INDEX_BY_DIM[dims]
model = InceptionV3([block_idx]).to(device)

# Calculate activation statistics for real and fake images
m1, s1 = calculate_activation_statistics(real_image_paths, model, device=device)
m2, s2 = calculate_activation_statistics(fake_image_paths, model, device=device)

# Calculate Frechet Inception Distance (FID)
fid_value = calculate_frechet_distance(m1, s1, m2, s2)

# Print the FID value
print(f"FID: {fid_value:.2f}")

import os
import random
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

# Path to the fake image directory
fake_dir = "./results_DG1/fake_images/"

# Get list of fake image files
fake_image_files = os.listdir(fake_dir)

# Randomly sample 16 fake images
fake_images_sample = random.sample(fake_image_files, 16)

# Create a 4x4 subplot grid
fig, axes = plt.subplots(4, 4, figsize=(8, 8))

# Plot fake images
for i, fake_image in enumerate(fake_images_sample):
    row, col = divmod(i, 4)
    img_path = os.path.join(fake_dir, fake_image)
    img = mpimg.imread(img_path)
    axes[row, col].imshow(img)
    axes[row, col].axis('off')

# Add a title to the grid
plt.suptitle('Fake Images', fontsize=16)

plt.tight_layout()
plt.show()

# Path to the real image directory
real_dir = "/content/drive/MyDrive/hw8_data/celeba_dataset_64x64/0/"

# Get list of real image files
real_image_files = os.listdir(real_dir)

# Randomly sample 16 real images
real_images_sample = random.sample(real_image_files, 16)

# Create a 4x4 subplot grid
fig, axes = plt.subplots(4, 4, figsize=(8, 8))

# Plot real images
for i, real_image in enumerate(real_images_sample):
    row, col = divmod(i, 4)
    img_path = os.path.join(real_dir, real_image)
    img = mpimg.imread(img_path)
    axes[row, col].imshow(img)
    axes[row, col].axis('off')

# Add a title to the grid
plt.suptitle('Real Images', fontsize=16)

plt.tight_layout()
plt.show()