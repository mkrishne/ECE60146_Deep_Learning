# -*- coding: utf-8 -*-
"""HW8_diffusion.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18_CDYnV5UF6xf_xIgkxzHhraEu9pJOR6
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/My Drive/hw8_data/DLStudio-2.4.3

!pip install pymsgbox

!python setup.py install

!pip install pycocotools

import os
import torch
import random
import numpy as np
import requests
import matplotlib.pyplot as plt
from tqdm import tqdm
from PIL import Image

seed = 60146
random.seed(seed)
torch.manual_seed(seed)
torch.cuda.manual_seed(seed)
np.random.seed(seed)
torch.backends.cudnn.deterministic=True
torch.backends.cudnn.benchmarks=False
os.environ['PYTHONHASHSEED'] = str(seed)

from GenerativeDiffusion import *

# Define Gaussian diffusion parameters
gauss_diffusion = GaussianDiffusion(
    num_diffusion_timesteps=1000,
)

# Define UNet model parameters
network = UNetModel(
    in_channels=3,
    model_channels=128,
    out_channels=3,
    num_res_blocks=2,
    attention_resolutions=(4, 8),  # for 64x64 images
    channel_mult=(1, 2, 3, 4),     # for 64x64 images
    num_heads=1,
    attention=True,                # Must be the same as for RunCodeForDiffusion.py
    # attention=False              # Must be the same as for RunCodeForDiffusion.py
)

# Define top-level parameters for Generative Diffusion
top_level = GenerativeDiffusion(
    gen_new_images=True,
    image_size=64,
    num_channels=128,
    ema_rate=0.9999,
    diffusion=gauss_diffusion,
    network=network,
    ngpu=1,
    path_saved_model="RESULTS_DIFFUSION2048",
    clip_denoised=True,
    num_samples=2048,
    batch_size_image_generation=8,
)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print('Device:', device)
# Load pre-trained model
model_path = "/content/drive/MyDrive/hw8_data/saved_models/diffusion.pt"

try:
    # Load the pre-trained model state dictionary
    network.load_state_dict(torch.load(model_path))

    # Move the model to the appropriate device
    network.to(top_level.device)

    # Set the model to evaluation mode
    network.eval()

    print("Starting Sampling...")

    # Initialize a list to store all sampled images
    all_images = []

    # Loop until the desired number of samples is reached
    while len(all_images) * top_level.batch_size_image_generation < top_level.num_samples:
        # Generate samples using the diffusion process
        sample = gauss_diffusion.p_sampler_for_image_generation(
            network,
            (top_level.batch_size_image_generation, 3, top_level.image_size, top_level.image_size),
            device=top_level.device,
            clip_denoised=top_level.clip_denoised,
        )

        # Scale the sample to [0, 255] and convert to uint8
        sample = ((sample + 1) * 127.5).clamp(0, 255).to(torch.uint8)

        # Permute the dimensions to match the expected image format
        sample = sample.permute(0, 2, 3, 1).contiguous()

        # Store the samples in a list
        all_images.extend([sample.cpu().numpy() for sample in [sample]])

        # Print progress
        print("Generated {} out of {} samples...".format(len(all_images) * top_level.batch_size_image_generation, top_level.num_samples))

    # Concatenate all sampled images and ensure the total number of samples matches the desired number
    arr = np.concatenate(all_images, axis=0)[:top_level.num_samples]

    # Convert the shape to a string for file naming
    shape_str = "x".join([str(x) for x in arr.shape])

    # Define the output path for the sampled images
    out_path = os.path.join(top_level.path_saved_model, f"samples_{shape_str}.npz")

    # Save the sampled images
    np.savez(out_path, arr)

    print("Image generation completed successfully.")

except Exception as e:
    print(f"An error occurred during image generation: {e}")

import os
import glob
import numpy as np
import torch
import torchvision
from PIL import Image
import matplotlib.pyplot as plt

# Path to the NPZ archive containing sampled images
npz_archive = "RESULTS_DIFFUSION2048/samples_2048x64x64x3.npz"

# Directory to save visualized samples
visualization_dir = "visualize_samples_diffusion2"

# Size to display the images
image_display_size = (64, 64)

# Clear visualization directory if it exists

if os.path.exists(visualization_dir):
    files = glob.glob(visualization_dir + "/*")
    for file in files:
        os.remove(file)
else:
    os.mkdir(visualization_dir)


# Load data from the NPZ archive
data = np.load(npz_archive)

# Visualize each image and save as JPG
for i, arr in enumerate(data['arr_0']):
    img = Image.fromarray(arr)
    img = img.resize(image_display_size)
    img.save(f"{visualization_dir}/test_{i+1000}.jpg")

import os

# Directory path
directory = "./celeba_dataset_64x64/"

# Get list of files in the directory
files = os.listdir(directory)

# Count the number of files
num_files = len(files)
# Print the number of files
print("Number of files in the directory:", num_files)

import os

# Directory path
directory = "./visualize_samples_diffusion2/"

# Get list of files in the directory
files = os.listdir(directory)

# Count the number of files
num_files = len(files)
# Print the number of files
print("Number of files in the directory:", num_files)

# Check if visualization directory exists
if os.path.exists(visualization_dir):
    # Load data from the NPZ archive
    data = np.load(npz_archive)

    # Convert numpy array to tensor and permute dimensions for visualization
    im_tensor_all = torch.from_numpy(data['arr_0']).float()
    im_tensor_all = im_tensor_all.permute(0, 3, 1, 2)

    # Create a grid of images
    grid_image = torchvision.utils.make_grid(im_tensor_all, nrow=16, padding=2, pad_value=1, normalize=True)

    # Plot the grid of images
    plt.figure(figsize=(64, 64))
    plt.imshow(np.transpose(grid_image.cpu(), (1, 2, 0)))
    plt.title("Fake Images")
    plt.axis('off')

    # Save the grid of images
    plt.savefig(os.path.join(visualization_dir, "fake_images.png"))
    plt.show()

!pip install pytorch-fid

import os
from pytorch_fid.fid_score import calculate_activation_statistics, calculate_frechet_distance
from pytorch_fid.inception import InceptionV3

# Define directories for real and fake images
fake_dir = "./visualize_samples_diffusion2/"
real_dir = "/content/drive/MyDrive/hw8_data/celeba_dataset_64x64/0/"
#real_dir = "./celeba_dataset_64x64/"

# Get the list of image files in the directories
real_image_paths = [os.path.join(real_dir, f) for f in os.listdir(real_dir) if os.path.isfile(os.path.join(real_dir, f))]
fake_image_paths = [os.path.join(fake_dir, f) for f in os.listdir(fake_dir) if os.path.isfile(os.path.join(fake_dir, f))]

# Specify the InceptionV3 model and dimensions
dims = 2048
block_idx = InceptionV3.BLOCK_INDEX_BY_DIM[dims]
model = InceptionV3([block_idx]).to(device)

# Calculate activation statistics for real and fake images
m1, s1 = calculate_activation_statistics(real_image_paths, model, device=device)
m2, s2 = calculate_activation_statistics(fake_image_paths, model, device=device)

# Calculate Frechet Inception Distance (FID)
fid_value = calculate_frechet_distance(m1, s1, m2, s2)

# Print the FID value
print(f"FID: {fid_value:.2f}")

import os
import random
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

# Path to the fake image directory
fake_dir = "./visualize_samples_diffusion/"

# Get list of fake image files
fake_image_files = os.listdir(fake_dir)

# Randomly sample 16 fake images
fake_images_sample = random.sample(fake_image_files, 16)

# Create a 4x4 subplot grid
fig, axes = plt.subplots(4, 4, figsize=(8, 8))

# Plot fake images
for i, fake_image in enumerate(fake_images_sample):
    row, col = divmod(i, 4)
    img_path = os.path.join(fake_dir, fake_image)
    img = mpimg.imread(img_path)
    axes[row, col].imshow(img)
    axes[row, col].axis('off')

# Add a title to the grid
plt.suptitle('Fake Images Diffusion', fontsize=16)

plt.tight_layout()
plt.show()